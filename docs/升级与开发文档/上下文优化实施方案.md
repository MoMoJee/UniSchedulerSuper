# Agent 上下文优化 - 实施方案 (基于 Token 和智能总结)

本文档描述如何实现基于 Token 数量和智能总结的 Agent 上下文优化机制。

## 概述

### 核心策略
- **不使用固定消息数**，改用 **Token 数量** 和 **窗口占比**
- **智能总结**：系统提示 + 历史总结 + 最近对话
- **动态计算**：基于实际 Token 使用情况调整保留的消息
- **用户配置化**：模型配置存储在 `core.UserData`，支持系统预置和用户自定义模型
- **Token 统计**：实时收集和存储用户的 Token 消耗量和费用

### 优化结构
```
发送给 LLM:
  [System Prompt (~2K tokens)]
  + [Summary of M1-M80 (~20K tokens)]
  + [Recent Messages M81-M100 (~50K tokens)]
  = Total ~72K tokens (60% of 128K window)
```

## 1. 文件结构

```
agent_service/
├── agent_graph.py              # 修改: agent_node 集成优化，从 UserData 读取配置
├── context_optimizer.py        # 新建: Token 计算和上下文优化
├── context_summarizer.py       # 新建: 智能总结逻辑
├── models.py                   # 修改: DialogStyle 添加优化开关
└── migrations/
    └── 00XX_add_context_optimization_switch.py  # 新建: 数据库迁移

core/
├── models.py                   # 修改: UserData 添加模型配置和 Token 统计
├── views.py                    # 修改: 添加模型配置和 Token 统计 API
└── migrations/
    └── 00XX_add_model_config_and_token_usage.py  # 新建: 数据库迁移

core/templates/ai_settings.html # 修改: 添加模型选择和 Token 统计显示
```

## 2. 实施步骤

### Step 1: 创建 Token 计算模块

**文件**: `agent_service/context_optimizer.py`

```python
"""
Token 计算和上下文优化模块
"""
import json
import logging
from typing import List, Optional, Dict
from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, AIMessage, ToolMessage

logger = logging.getLogger(__name__)


class TokenCalculator:
    """
    Token 计算器
    
    支持三种计算方式（按优先级）:
    1. actual: 从 LangGraph response_metadata 读取实际 Token（最准确）
    2. tiktoken: 使用 tiktoken 库精确计算
    3. estimate: 粗略估算（兜底）
    """
    
    def __init__(self, method: str = "actual", model: str = "gpt-3.5-turbo"):
        """
        初始化 Token 计算器
        
        Args:
            method: 计算方式 - actual/tiktoken/estimate
            model: 模型名称，用于 tiktoken
        """
        self.method = method
        self.encoding = None
        
        if method == "tiktoken":
            try:
                import tiktoken
                self.encoding = tiktoken.encoding_for_model(model)
                logger.info(f"[Token计算] 使用 tiktoken 编码: {model}")
            except Exception as e:
                logger.warning(f"[Token计算] tiktoken 初始化失败: {e}，降级到估算模式")
                self.method = "estimate"
    
    def calculate_messages(
        self, 
        messages: List[BaseMessage],
        usage_metadata: Optional[Dict] = None
    ) -> int:
        """
        计算消息列表的 Token 数
        
        Args:
            messages: 消息列表
            usage_metadata: LangGraph 返回的实际使用统计（优先）
            
        Returns:
            Token 数量
        """
        # 方法 1: 使用实际统计（来自 response.response_metadata['usage']）
        if self.method == "actual" and usage_metadata:
            prompt_tokens = usage_metadata.get('prompt_tokens', 0)
            if prompt_tokens > 0:
                logger.debug(f"[Token计算] 使用实际统计: {prompt_tokens} tokens")
                return prompt_tokens
        
        # 方法 2: 使用 tiktoken 精确计算
        if self.method == "tiktoken" and self.encoding:
            total = 0
            for msg in messages:
                content = self._get_message_content(msg)
                try:
                    total += len(self.encoding.encode(content))
                except Exception as e:
                    logger.warning(f"[Token计算] tiktoken 编码失败: {e}")
                    # 降级到估算
                    total += int(len(content) / 2.5)
            logger.debug(f"[Token计算] tiktoken 计算: {total} tokens")
            return total
        
        # 方法 3: 粗略估算
        total_chars = sum(len(self._get_message_content(msg)) for msg in messages)
        estimated = int(total_chars / 2.5)
        logger.debug(f"[Token计算] 粗略估算: {estimated} tokens")
        return estimated
    
    def calculate_text(self, text: str) -> int:
        """计算文本的 Token 数"""
        if self.method == "tiktoken" and self.encoding:
            try:
                return len(self.encoding.encode(text))
            except:
                pass
        return int(len(text) / 2.5)
    
    def _get_message_content(self, msg: BaseMessage) -> str:
        """提取消息内容为文本"""
        content = getattr(msg, 'content', '')
        if isinstance(content, list):
            return ' '.join(str(item) for item in content)
        return str(content)


class ToolMessageCompressor:
    """工具消息压缩器"""
    
    def __init__(self, max_tokens: int = 200):
        self.max_tokens = max_tokens
    
    def compress(self, msg: ToolMessage, calculator: TokenCalculator) -> ToolMessage:
        """
        压缩工具消息
        
        策略:
        1. 解析 JSON，智能总结
        2. 长文本截断
        3. 保留 tool_call_id 和 name
        """
        try:
            content = msg.content
            current_tokens = calculator.calculate_text(content)
            
            if current_tokens <= self.max_tokens:
                return msg
            
            # 尝试解析 JSON
            if isinstance(content, str) and content.strip().startswith(('{', '[')):
                try:
                    data = json.loads(content)
                    summary = self._summarize_data(data, msg.name)
                    return ToolMessage(
                        content=summary,
                        tool_call_id=msg.tool_call_id,
                        name=msg.name
                    )
                except json.JSONDecodeError:
                    pass
            
            # 直接截断
            max_chars = self.max_tokens * 2  # 粗略估算
            if len(content) > max_chars:
                truncated = (
                    content[:max_chars // 2] + 
                    "\n...(已压缩)...\n" + 
                    content[-(max_chars // 4):]
                )
                return ToolMessage(
                    content=truncated,
                    tool_call_id=msg.tool_call_id,
                    name=msg.name
                )
            
            return msg
            
        except Exception as e:
            logger.warning(f"[工具压缩] 失败: {e}")
            return msg
    
    def _summarize_data(self, data, tool_name: Optional[str] = None) -> str:
        """智能总结 JSON 数据"""
        # 搜索结果
        if 'items' in data or 'results' in data:
            items = data.get('items') or data.get('results', [])
            total = len(items)
            if total == 0:
                return "查询结果: 未找到"
            
            preview = []
            for i, item in enumerate(items[:3]):
                idx = item.get('search_index', i + 1)
                title = item.get('title', 'Unknown')
                item_type = item.get('type', '')
                preview.append(f"#{idx} {title}")
            
            preview_str = ', '.join(preview)
            if total > 3:
                preview_str += f" ...等共{total}项"
            return f"查询成功: {preview_str}"
        
        # 创建/更新/删除结果
        if 'id' in data or 'uid' in data:
            title = data.get('title', 'Unknown')
            if 'create' in (tool_name or ''):
                return f"已创建: {title}"
            elif 'update' in (tool_name or ''):
                return f"已更新: {title}"
            elif 'delete' in (tool_name or ''):
                return f"已删除: {title}"
            return f"操作成功: {title}"
        
        # 列表
        if isinstance(data, list):
            return f"返回 {len(data)} 项"
        
        # 默认
        json_str = json.dumps(data, ensure_ascii=False)
        return json_str[:self.max_tokens * 2] + "..."
```

### Step 2: 创建智能总结模块

**文件**: `agent_service/context_summarizer.py`

```python
"""
对话历史智能总结模块
"""
import logging
import datetime
from typing import List, Dict, Optional
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, SystemMessage

logger = logging.getLogger(__name__)


class ConversationSummarizer:
    """对话总结器"""
    
    def __init__(
        self,
        llm,
        token_calculator,
        target_summary_tokens: int = 20000,
        min_messages: int = 20,
        trigger_ratio: float = 0.5
    ):
        """
        初始化总结器
        
        Args:
            llm: LLM 实例
            token_calculator: Token 计算器
            target_summary_tokens: 目标总结 Token 数
            min_messages: 最少消息数才开始总结
            trigger_ratio: 触发重新总结的比例阈值
        """
        self.llm = llm
        self.token_calculator = token_calculator
        self.target_summary_tokens = target_summary_tokens
        self.min_messages = min_messages
        self.trigger_ratio = trigger_ratio
    
    def should_summarize(
        self,
        messages: List[BaseMessage],
        summary_metadata: Optional[Dict]
    ) -> bool:
        """
        判断是否需要触发总结
        
        条件:
        1. 消息数 >= min_messages
        2. 没有总结 OR 新消息 Token 数 > 历史总结的 trigger_ratio
        """
        if len(messages) < self.min_messages:
            logger.debug(f"[总结检查] 消息数 {len(messages)} < {self.min_messages}，跳过")
            return False
        
        # 首次总结
        if not summary_metadata:
            logger.info("[总结检查] 没有历史总结，准备首次总结")
            return True
        
        # 检查新增消息比例
        summarized_until = summary_metadata.get('summarized_until', 0)
        summary_tokens = summary_metadata.get('summary_tokens', 0)
        
        if summarized_until >= len(messages):
            logger.debug("[总结检查] 所有消息已总结")
            return False
        
        new_messages = messages[summarized_until:]
        new_tokens = self.token_calculator.calculate_messages(new_messages)
        
        if summary_tokens == 0:
            ratio = float('inf')
        else:
            ratio = new_tokens / summary_tokens
        
        should_trigger = ratio > self.trigger_ratio
        
        logger.info(
            f"[总结检查] 新消息: {len(new_messages)}条 ({new_tokens}t), "
            f"历史总结: {summary_tokens}t, "
            f"比例: {ratio:.1%}, "
            f"阈值: {self.trigger_ratio:.1%}, "
            f"触发: {should_trigger}"
        )
        
        return should_trigger
    
    async def summarize(
        self,
        messages: List[BaseMessage],
        previous_summary: Optional[str] = None
    ) -> Dict:
        """
        总结消息历史
        
        Args:
            messages: 要总结的消息列表
            previous_summary: 之前的总结（如果有）
            
        Returns:
            {
                "summary": "总结文本",
                "summarized_until": 消息索引,
                "summary_tokens": Token 数,
                "created_at": 创建时间,
                "message_count": 消息数量
            }
        """
        logger.info(f"[总结] 开始总结 {len(messages)} 条消息...")
        
        # 格式化对话历史
        conversation_text = self._format_messages(messages)
        current_tokens = self.token_calculator.calculate_messages(messages)
        
        # 构建总结提示
        prompt = self._build_summary_prompt(
            conversation_text,
            len(messages),
            current_tokens,
            previous_summary
        )
        
        # 调用 LLM
        try:
            response = await self.llm.ainvoke([HumanMessage(content=prompt)])
            summary_text = response.content
            summary_tokens = self.token_calculator.calculate_text(summary_text)
            
            compression_ratio = (1 - summary_tokens / current_tokens) * 100 if current_tokens > 0 else 0
            
            logger.info(
                f"[总结完成] 原始: {len(messages)}条 ({current_tokens}t), "
                f"总结: {summary_tokens}t, "
                f"压缩率: {compression_ratio:.1f}%"
            )
            
            return {
                "summary": summary_text,
                "summarized_until": len(messages),
                "summary_tokens": summary_tokens,
                "created_at": datetime.datetime.now().isoformat(),
                "message_count": len(messages),
                "original_tokens": current_tokens
            }
            
        except Exception as e:
            logger.error(f"[总结失败] {e}")
            raise
    
    def _format_messages(self, messages: List[BaseMessage]) -> str:
        """格式化消息为文本"""
        lines = []
        for i, msg in enumerate(messages, 1):
            if isinstance(msg, SystemMessage):
                continue  # 跳过系统消息
            
            role = self._get_role(msg)
            content = self._get_content(msg)
            lines.append(f"[{i}] {role}: {content}")
        
        return '\n'.join(lines)
    
    def _get_role(self, msg: BaseMessage) -> str:
        """获取消息角色"""
        if isinstance(msg, HumanMessage):
            return "用户"
        elif isinstance(msg, AIMessage):
            return "AI"
        elif isinstance(msg, ToolMessage):
            return f"工具({msg.name})"
        return "系统"
    
    def _get_content(self, msg: BaseMessage) -> str:
        """获取消息内容（简化）"""
        content = getattr(msg, 'content', '')
        
        if isinstance(content, str):
            # 限制长度
            if len(content) > 500:
                return content[:250] + "..." + content[-100:]
            return content
        
        return str(content)[:500]
    
    def _build_summary_prompt(
        self,
        conversation: str,
        message_count: int,
        current_tokens: int,
        previous_summary: Optional[str]
    ) -> str:
        """构建总结提示词"""
        base_prompt = f"""请总结以下对话历史，保留关键信息。

## 对话历史
共 {message_count} 条消息，约 {current_tokens} tokens

{conversation}

## 总结要求
1. **提取核心信息**: 用户的主要意图、需求和目标
2. **记录关键操作**: 重要的决策和操作结果
3. **保留关键数据**: 时间、地点、人物、数量等具体信息
4. **压缩冗余内容**: 工具调用细节、重复问答等
5. **目标长度**: 约 {self.target_summary_tokens} tokens

## 输出格式
简洁的段落式总结，保持时间顺序，重点突出关键信息。
"""
        
        if previous_summary:
            base_prompt = f"""## 之前的总结
{previous_summary}

## 新的对话内容
{conversation}

请基于之前的总结，整合新的对话内容，生成更新后的完整总结。

{base_prompt}
"""
        
        return base_prompt
```

```python
"""
Agent 上下文优化模块
在发送给 LLM 之前动态优化消息列表，减少 Token 消耗
"""
import json
import logging
from typing import List, Optional
from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, AIMessage, ToolMessage

logger = logging.getLogger(__name__)


class ContextOptimizer:
    """
    上下文优化器
    
    职责:
    1. 应用滑动窗口策略保留最近 N 条消息
    2. 压缩工具输出内容
    3. 估算 Token 使用量
    4. 记录优化指标
    """
    
    def __init__(
        self,
        max_messages: int = 20,
        compress_tool_output: bool = True,
        tool_output_max_length: int = 500,
        enable_logging: bool = True
    ):
        """
        初始化优化器
        
        Args:
            max_messages: 保留的最大消息数（不含 SystemMessage）
            compress_tool_output: 是否压缩工具输出
            tool_output_max_length: 工具输出的最大字符数
            enable_logging: 是否启用详细日志
        """
        self.max_messages = max_messages
        self.compress_tool_output = compress_tool_output
        self.tool_output_max_length = tool_output_max_length
        self.enable_logging = enable_logging
    
    def optimize(self, messages: List[BaseMessage]) -> List[BaseMessage]:
        """
        优化消息列表
        
        Args:
            messages: 完整的消息历史
            
        Returns:
            优化后的消息列表
        """
        if not messages:
            return messages
        
        original_count = len(messages)
        
        # 1. 分离 SystemMessage（总是保留最后一个）
        system_messages = [m for m in messages if isinstance(m, SystemMessage)]
        other_messages = [m for m in messages if not isinstance(m, SystemMessage)]
        
        # 只保留最新的 SystemMessage（通常每次调用都会重建）
        if system_messages:
            system_messages = [system_messages[-1]]
        
        # 2. 应用滑动窗口
        if len(other_messages) > self.max_messages:
            if self.enable_logging:
                logger.info(
                    f"[上下文优化] 消息数 {len(other_messages)} 超过阈值 {self.max_messages}，"
                    f"保留最近 {self.max_messages} 条"
                )
            other_messages = other_messages[-self.max_messages:]
        
        # 3. 压缩工具输出
        if self.compress_tool_output:
            compressed = []
            tool_compressed_count = 0
            for msg in other_messages:
                if isinstance(msg, ToolMessage):
                    compressed_msg = self._compress_tool_message(msg)
                    compressed.append(compressed_msg)
                    if compressed_msg.content != msg.content:
                        tool_compressed_count += 1
                else:
                    compressed.append(msg)
            other_messages = compressed
            
            if self.enable_logging and tool_compressed_count > 0:
                logger.debug(f"[上下文优化] 压缩了 {tool_compressed_count} 个工具输出")
        
        # 4. 组装最终列表
        optimized = system_messages + other_messages
        
        # 5. 记录统计信息
        if self.enable_logging:
            compression_rate = (1 - len(optimized) / original_count) * 100 if original_count > 0 else 0
            logger.info(
                f"[上下文优化] 原始: {original_count} 条, "
                f"优化后: {len(optimized)} 条, "
                f"压缩率: {compression_rate:.1f}%"
            )
        
        return optimized
    
    def _compress_tool_message(self, msg: ToolMessage) -> ToolMessage:
        """
        压缩工具消息的内容
        
        策略:
        1. 解析 JSON 数据，提取关键信息
        2. 如果无法解析，直接截断长内容
        3. 保留 tool_call_id 和 name（必须）
        """
        try:
            content = msg.content
            
            # 策略 1: 尝试解析并总结 JSON
            if isinstance(content, str) and content.strip().startswith(('{', '[')):
                try:
                    data = json.loads(content)
                    summary = self._summarize_tool_output(data, msg.name)
                    
                    return ToolMessage(
                        content=summary,
                        tool_call_id=msg.tool_call_id,
                        name=msg.name
                    )
                except json.JSONDecodeError:
                    pass
            
            # 策略 2: 直接截断长内容
            if isinstance(content, str) and len(content) > self.tool_output_max_length:
                truncated = (
                    content[:self.tool_output_max_length // 2] + 
                    "\n...(中间内容已省略)...\n" + 
                    content[-(self.tool_output_max_length // 4):]
                )
                return ToolMessage(
                    content=truncated,
                    tool_call_id=msg.tool_call_id,
                    name=msg.name
                )
            
            # 策略 3: 内容不长，保持原样
            return msg
            
        except Exception as e:
            logger.warning(f"[上下文优化] 压缩工具消息失败: {e}")
            return msg
    
    def _summarize_tool_output(self, data: dict, tool_name: Optional[str] = None) -> str:
        """
        根据工具类型智能总结输出
        
        不同工具的输出格式不同，需要针对性处理:
        - search_items: 返回列表，总结为 "找到 N 个项目: #1 xxx, #2 yyy..."
        - create_item: 返回创建的对象，总结为 "已创建: xxx"
        - update_item: 返回更新结果，总结为 "已更新: xxx"
        - delete_item: 返回删除结果，总结为 "已删除: xxx"
        """
        # 搜索结果 (search_items)
        if 'items' in data or 'results' in data:
            items = data.get('items') or data.get('results', [])
            total = len(items)
            
            if total == 0:
                return "查询结果: 未找到匹配项"
            
            # 提取前3项作为预览
            preview_items = []
            for i, item in enumerate(items[:3]):
                index = item.get('search_index', i + 1)
                title = item.get('title', '未知')
                item_type = item.get('type', '')
                preview_items.append(f"#{index} {title} ({item_type})")
            
            preview = ', '.join(preview_items)
            if total > 3:
                preview += f" ...等共 {total} 项"
            
            return f"查询成功: {preview}"
        
        # 创建/更新结果 (create_item, update_item)
        if 'id' in data or 'uid' in data:
            title = data.get('title', '未知')
            item_type = data.get('type', '')
            
            if tool_name and 'create' in tool_name:
                return f"已创建: {title} ({item_type})"
            elif tool_name and 'update' in tool_name:
                return f"已更新: {title}"
            elif tool_name and 'delete' in tool_name:
                return f"已删除: {title}"
            else:
                return f"操作成功: {title}"
        
        # 布尔结果 (删除、完成等)
        if isinstance(data, dict) and 'success' in data:
            success = data.get('success', False)
            message = data.get('message', '')
            if success:
                return f"操作成功: {message}" if message else "操作成功"
            else:
                return f"操作失败: {message}" if message else "操作失败"
        
        # 列表数据 (get_event_groups 等)
        if isinstance(data, list):
            return f"返回 {len(data)} 项数据"
        
        # 默认: 保留简短的 JSON
        json_str = json.dumps(data, ensure_ascii=False)
        if len(json_str) <= self.tool_output_max_length:
            return json_str
        else:
            return json_str[:self.tool_output_max_length] + "...(已截断)"
    
    def estimate_tokens(self, messages: List[BaseMessage]) -> int:
        """
        粗略估算消息的 Token 数量
        
        估算规则 (粗略):
        - 英文: 1 token ≈ 4 字符
        - 中文: 1 token ≈ 1.5 字符
        - 简化: 统一按 1 token ≈ 2.5 字符
        """
        total_chars = 0
        for msg in messages:
            content = getattr(msg, 'content', '')
            if isinstance(content, str):
                total_chars += len(content)
            elif isinstance(content, list):
                total_chars += sum(len(str(item)) for item in content)
        
        # 粗略估算: 1 token ≈ 2.5 字符
        estimated_tokens = int(total_chars / 2.5)
        return estimated_tokens


# 全局单例（使用默认配置）
_default_optimizer = None

def get_default_optimizer() -> ContextOptimizer:
    """获取默认的优化器实例"""
    global _default_optimizer
    if _default_optimizer is None:
        _default_optimizer = ContextOptimizer()
    return _default_optimizer


def optimize_messages_for_llm(
    messages: List[BaseMessage],
    max_messages: int = 20,
    compress_tool_output: bool = True
) -> List[BaseMessage]:
    """
    便捷函数: 优化消息列表用于发送给 LLM
    
    Args:
        messages: 完整的消息历史
        max_messages: 保留的最大消息数
        compress_tool_output: 是否压缩工具输出
        
    Returns:
        优化后的消息列表
    """
    optimizer = ContextOptimizer(
        max_messages=max_messages,
        compress_tool_output=compress_tool_output
    )
    return optimizer.optimize(messages)
### Step 3: 修改 Agent State 定义

**文件**: `agent_service/agent_graph.py`

在 `AgentState` 中添加总结元数据字段：

```python
class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    active_tools: List[str]  # 当前启用的工具名称列表
    
    # ===== 新增: 总结元数据 =====
    summary_metadata: Optional[Dict]  # 历史总结的元数据
    # 结构: {
    #   "summary": "总结文本",
    #   "summarized_until": 80,  # 总结到第 80 条消息
    #   "summary_tokens": 20000,
    #   "created_at": "2026-01-01T10:00:00",
    #   "message_count": 80,
    #   "original_tokens": 92000
    # }
```

### Step 4: 扩展 UserData 模型 - 模型配置和 Token 统计

**文件**: `core/models.py`

```python
from django.db import models
from django.contrib.auth.models import User
import json

class UserData(models.Model):
    user = models.OneToOneField(User, on_delete=models.CASCADE, related_name='user_data')
    
    # ... 现有字段 ...
    
    # ===== Agent 模型配置 =====
    agent_model_config = models.JSONField(
        default=dict,
        blank=True,
        verbose_name="Agent 模型配置",
        help_text="存储用户的 Agent 模型配置"
    )
    # 结构示例:
    # {
    #   "current_model_id": "system_deepseek",  # 当前使用的模型 ID
    #   "models": {
    #     "system_deepseek": {
    #       "name": "DeepSeek Chat",
    #       "provider": "system",  # system 或 custom
    #       "api_url": "https://api.deepseek.com/v1/chat/completions",
    #       "api_key": "从环境变量读取",
    #       "context_window": 128000,
    #       "supports_tools": true,
    #       "cost_per_1k_input": 0.00014,  # 美元
    #       "cost_per_1k_output": 0.00028
    #     },
    #     "custom_model_1": {
    #       "name": "我的 GPT-4",
    #       "provider": "custom",
    #       "api_url": "https://api.openai.com/v1/chat/completions",
    #       "api_key": "用户输入的密钥",
    #       "context_window": 128000,
    #       "supports_tools": true,
    #       "cost_per_1k_input": 0.01,
    #       "cost_per_1k_output": 0.03
    #     }
    #   }
    # }
    
    # ===== Token 消耗统计 =====
    token_usage_stats = models.JSONField(
        default=dict,
        blank=True,
        verbose_name="Token 消耗统计",
        help_text="记录用户的 Token 使用情况"
    )
    # 结构示例:
    # {
    #   "total_input_tokens": 1500000,
    #   "total_output_tokens": 500000,
    #   "total_cost": 12.50,  # 美元
    #   "quota": 9999999,  # 暂时设为大值
    #   "last_updated": "2026-01-02T10:00:00",
    #   "daily_stats": {
    #     "2026-01-02": {
    #       "input_tokens": 50000,
    #       "output_tokens": 20000,
    #       "cost": 0.45
    #     }
    #   },
    #   "model_stats": {
    #     "system_deepseek": {
    #       "input_tokens": 1200000,
    #       "output_tokens": 400000,
    #       "cost": 10.20
    #     }
    #   }
    # }
    
    # ===== 上下文优化配置 =====
    context_optimization_config = models.JSONField(
        default=dict,
        blank=True,
        verbose_name="上下文优化配置",
        help_text="Token 优化和总结的配置参数"
    )
    # 结构示例:
    # {
    #   "enable_optimization": true,
    #   "target_usage_ratio": 0.6,
    #   "token_calculation_method": "actual",  # actual/tiktoken/estimate
    #   "summary_token_ratio": 0.26,
    #   "recent_token_ratio": 0.65,
    #   "enable_summarization": true,
    #   "summary_trigger_ratio": 0.5,
    #   "min_messages_before_summary": 20,
    #   "compress_tool_output": true,
    #   "tool_output_max_tokens": 200
    # }
    
    def get_current_model_config(self):
        """获取当前使用的模型配置"""
        config = self.agent_model_config or {}
        current_id = config.get('current_model_id', 'system_deepseek')
        models = config.get('models', {})
        return models.get(current_id, self._get_default_model_config())
    
    def _get_default_model_config(self):
        """返回默认的系统模型配置"""
        return {
            "name": "DeepSeek Chat",
            "provider": "system",
            "api_url": "https://api.deepseek.com/v1/chat/completions",
            "api_key": "从环境变量读取",
            "context_window": 128000,
            "supports_tools": True,
            "cost_per_1k_input": 0.00014,
            "cost_per_1k_output": 0.00028
        }
    
    def get_optimization_config(self):
        """获取上下文优化配置"""
        config = self.context_optimization_config or {}
        return {
            "enable_optimization": config.get('enable_optimization', True),
            "target_usage_ratio": config.get('target_usage_ratio', 0.6),
            "token_calculation_method": config.get('token_calculation_method', 'actual'),
            "summary_token_ratio": config.get('summary_token_ratio', 0.26),
            "recent_token_ratio": config.get('recent_token_ratio', 0.65),
            "enable_summarization": config.get('enable_summarization', True),
            "summary_trigger_ratio": config.get('summary_trigger_ratio', 0.5),
            "min_messages_before_summary": config.get('min_messages_before_summary', 20),
            "compress_tool_output": config.get('compress_tool_output', True),
            "tool_output_max_tokens": config.get('tool_output_max_tokens', 200),
        }
    
    def update_token_usage(self, input_tokens: int, output_tokens: int, model_id: str, cost: float = 0):
        """更新 Token 使用统计"""
        from datetime import datetime
        
        stats = self.token_usage_stats or {}
        
        # 更新总计
        stats['total_input_tokens'] = stats.get('total_input_tokens', 0) + input_tokens
        stats['total_output_tokens'] = stats.get('total_output_tokens', 0) + output_tokens
        stats['total_cost'] = stats.get('total_cost', 0) + cost
        stats['quota'] = stats.get('quota', 9999999)
        stats['last_updated'] = datetime.now().isoformat()
        
        # 更新每日统计
        today = datetime.now().strftime('%Y-%m-%d')
        daily_stats = stats.get('daily_stats', {})
        if today not in daily_stats:
            daily_stats[today] = {'input_tokens': 0, 'output_tokens': 0, 'cost': 0}
        daily_stats[today]['input_tokens'] += input_tokens
        daily_stats[today]['output_tokens'] += output_tokens
        daily_stats[today]['cost'] += cost
        stats['daily_stats'] = daily_stats
        
        # 更新模型统计
        model_stats = stats.get('model_stats', {})
        if model_id not in model_stats:
            model_stats[model_id] = {'input_tokens': 0, 'output_tokens': 0, 'cost': 0}
        model_stats[model_id]['input_tokens'] += input_tokens
        model_stats[model_id]['output_tokens'] += output_tokens
        model_stats[model_id]['cost'] += cost
        stats['model_stats'] = model_stats
        
        self.token_usage_stats = stats
        self.save(update_fields=['token_usage_stats'])
    
    def get_token_usage_summary(self):
        """获取 Token 使用摘要"""
        stats = self.token_usage_stats or {}
        return {
            'total_tokens': stats.get('total_input_tokens', 0) + stats.get('total_output_tokens', 0),
            'input_tokens': stats.get('total_input_tokens', 0),
            'output_tokens': stats.get('total_output_tokens', 0),
            'total_cost': stats.get('total_cost', 0),
            'quota': stats.get('quota', 9999999),
            'remaining': stats.get('quota', 9999999) - stats.get('total_input_tokens', 0) - stats.get('total_output_tokens', 0),
        }

    class Meta:
        db_table = 'core_userdata'
        verbose_name = '用户数据'
        verbose_name_plural = '用户数据'
```

### Step 5: 修改 DialogStyle 模型（仅保留开关）

**文件**: `agent_service/models.py`

```python
class DialogStyle(models.Model):
    # ... 现有字段 ...
    
    # ===== 上下文优化开关（简化版）=====
    enable_context_optimization = models.BooleanField(
        default=True,
        verbose_name="启用上下文优化",
        help_text="是否启用基于 Token 的上下文优化（详细配置在用户设置中）"
    )

    
    # Token 分配策略
    summary_token_ratio = models.FloatField(
        default=0.26,
        verbose_name="历史总结占比",
        help_text="历史总结 Token 占总预算的比例"
    )
    
    recent_token_ratio = models.FloatField(
        default=0.65,
        verbose_name="最近对话占比",
        help_text="最近对话 Token 占总预算的比例"
    )
    
    # 总结配置
    enable_summarization = models.BooleanField(
        default=True,
        verbose_name="启用智能总结",
        help_text="是否自动总结旧对话历史"
    )
    
    summary_trigger_ratio = models.FloatField(
        default=0.5,
        verbose_name="总结触发阈值",
        help_text="当新消息 Token 超过历史总结的此比例时触发重新总结"
    )
    
    min_messages_before_summary = models.IntegerField(
        default=20,
        verbose_name="总结最少消息数",
        help_text="至少多少条消息才开始总结"
    )
    
    # 工具输出压缩
    compress_tool_output = models.BooleanField(
        default=True,
        verbose_name="压缩工具输出",
        help_text="是否压缩工具调用的返回内容"
    )
    
    tool_output_max_tokens = models.IntegerField(
        default=200,
        verbose_name="工具输出最大 Token",
        help_text="单个工具输出压缩后的最大 Token 数"
    )
    
    # Token 计算方式
    token_calculation_method = models.CharField(
        max_length=20,
        default='actual',
        choices=[
            ('actual', '实际统计（推荐）'),
            ('tiktoken', 'Tiktoken 精确计算'),
            ('estimate', '粗略估算'),
        ],
        verbose_name="Token 计算方式",
        help_text="Token 数量的计算方法"
    )
    
    @property
    def target_total_tokens(self) -> int:
        """计算目标总 Token 数"""
        return int(self.model_window_size * self.target_usage_ratio)
    
    @property
    def summary_token_budget(self) -> int:
        """计算历史总结的 Token 预算"""
        return int(self.target_total_tokens * self.summary_token_ratio)
    
    @property
    def recent_token_budget(self) -> int:
        """计算最近对话的 Token 预算"""
        return int(self.target_total_tokens * self.recent_token_ratio)
    
    class Meta:
        verbose_name = "对话风格"
        verbose_name_plural = "对话风格"
```

### Step 6: 集成到 agent_node（从 UserData 读取配置）

**文件**: `agent_service/agent_graph.py`

```python
def agent_node(state: AgentState, config: RunnableConfig) -> dict:
    """
    统一的 Agent 节点，支持智能上下文优化
    """
    from agent_service.context_optimizer import TokenCalculator, ToolMessageCompressor
    from agent_service.context_summarizer import ConversationSummarizer
    from agent_service.models import DialogStyle
    from core.models import UserData
    
    messages = state['messages']
    summary_metadata = state.get('summary_metadata')
    
    # 获取配置
    configurable = config.get("configurable", {})
    active_tool_names = configurable.get("active_tools") or state.get('active_tools') or get_default_tools()
    user = configurable.get("user")
    
    # ... 现有日志代码 ...
    
    # 获取当前时间
    now = datetime.datetime.now()
    current_time = now.strftime("%Y-%m-%d %H:%M:%S")
    
    # ===== 1. 加载用户配置 =====
    try:
        if user and user.is_authenticated:
            # 从 UserData 获取模型配置和优化配置
            user_data = UserData.objects.get(user=user)
            model_config = user_data.get_current_model_config()
            opt_config = user_data.get_optimization_config()
            
            # 从 DialogStyle 获取开关
            style = DialogStyle.get_or_create_default(user)
            enable_optimization = style.enable_context_optimization and opt_config['enable_optimization']
            
            # 记录当前使用的模型
            current_model_id = user_data.agent_model_config.get('current_model_id', 'system_deepseek')
            
        else:
            # 未登录用户使用默认配置
            model_config = {
                "name": "DeepSeek Chat",
                "context_window": 128000,
                "cost_per_1k_input": 0.00014,
                "cost_per_1k_output": 0.00028
            }
            opt_config = {
                "enable_optimization": True,
                "target_usage_ratio": 0.6,
                "token_calculation_method": "actual",
                "summary_token_ratio": 0.26,
                "recent_token_ratio": 0.65,
                "enable_summarization": True,
                "summary_trigger_ratio": 0.5,
                "min_messages_before_summary": 20,
                "compress_tool_output": True,
                "tool_output_max_tokens": 200,
            }
            enable_optimization = True
            current_model_id = "system_deepseek"
            
    except Exception as e:
        logger.warning(f"[优化] 加载配置失败: {e}")
        # 使用默认配置
        model_config = {"context_window": 128000}
        opt_config = {"enable_optimization": False}
        enable_optimization = False
        current_model_id = "unknown"
    
    # ===== 2. 计算 Token 预算 =====
    model_window = model_config.get('context_window', 128000)
    target_tokens = int(model_window * opt_config.get('target_usage_ratio', 0.6))
    system_tokens = 2000  # System Prompt 预估
    summary_token_budget = int(target_tokens * opt_config.get('summary_token_ratio', 0.26))
    recent_token_budget = int(target_tokens * opt_config.get('recent_token_ratio', 0.65))
    
    logger.info(
        f"[优化] 配置加载: 模型={model_config['name']}, "
        f"窗口={model_window}, 目标={target_tokens}, "
        f"优化={enable_optimization}"
    )
    
    # ===== 3. 初始化优化组件 =====
    token_calculator = TokenCalculator(
        method=opt_config.get('token_calculation_method', 'actual'),
        model="gpt-3.5-turbo"
    )
    
    tool_compressor = None
    if opt_config.get('compress_tool_output', True):
        tool_compressor = ToolMessageCompressor(
            max_tokens=opt_config.get('tool_output_max_tokens', 200)
        )
    
    summarizer = None
    if opt_config.get('enable_summarization', True):
        summarizer = ConversationSummarizer(
            llm=llm,
            token_calculator=token_calculator,
            target_summary_tokens=summary_token_budget,
            min_messages=opt_config.get('min_messages_before_summary', 20),
            trigger_ratio=opt_config.get('summary_trigger_ratio', 0.5)
        )
    
    # ===== 4. 检查是否需要总结 =====
    new_summary_metadata = summary_metadata
    
    if enable_optimization and summarizer:
        if summarizer.should_summarize(messages, summary_metadata):
            try:
                logger.info("[优化] 触发智能总结...")
                
                # 异步总结（如果之前有总结，传入以便增量更新）
                previous_summary = summary_metadata.get('summary') if summary_metadata else None
                new_summary_metadata = await summarizer.summarize(
                    messages,
                    previous_summary
                )
                
                logger.info(
                    f"[优化] 总结完成: {new_summary_metadata['message_count']}条 → "
                    f"{new_summary_metadata['summary_tokens']}t"
                )
                
            except Exception as e:
                logger.error(f"[优化] 总结失败: {e}")
                # 总结失败不影响主流程，继续使用旧总结或无总结
    
    # ===== 5. 构建优化的上下文 =====
    if enable_optimization:
        optimized_messages = await build_optimized_context(
            user=user,
            active_tool_names=active_tool_names,
            current_time=current_time,
            messages=messages,
            summary_metadata=new_summary_metadata,
            token_calculator=token_calculator,
            tool_compressor=tool_compressor,
            system_tokens=system_tokens,
            summary_token_budget=summary_token_budget,
            recent_token_budget=recent_token_budget
        )
    else:
        # 不优化，使用完整历史
        optimized_messages = build_full_context(
            user=user,
            active_tool_names=active_tool_names,
            current_time=current_time,
            messages=messages
        )
    
    # ===== 6. 调用 LLM =====
    try:
        response = await llm_with_tools.ainvoke(optimized_messages)
        
        # ===== 7. 提取并记录 Token 使用 =====
        if user and user.is_authenticated:
            try:
                usage = response.response_metadata.get('usage', {})
                input_tokens = usage.get('prompt_tokens', 0)
                output_tokens = usage.get('completion_tokens', 0)
                
                # 计算费用
                cost = (
                    input_tokens / 1000 * model_config.get('cost_per_1k_input', 0) +
                    output_tokens / 1000 * model_config.get('cost_per_1k_output', 0)
                )
                
                # 更新 UserData 的统计
                user_data.update_token_usage(
                    input_tokens=input_tokens,
                    output_tokens=output_tokens,
                    model_id=current_model_id,
                    cost=cost
                )
                
                logger.info(
                    f"[Token] 用户={user.username}, "
                    f"输入={input_tokens}, 输出={output_tokens}, "
                    f"费用=${cost:.4f}, 模型={current_model_id}"
                )
                
            except Exception as e:
                logger.error(f"[Token] 统计失败: {e}")
        
        # 返回结果
        return {
            "messages": [response],
            "summary_metadata": new_summary_metadata
        }
        
    except Exception as e:
        logger.error(f"[Agent] LLM 调用失败: {e}")
        raise


async def build_optimized_context(
    user,
    active_tool_names: List[str],
    current_time: str,
    messages: List[BaseMessage],
    summary_metadata: Optional[Dict],
    token_calculator: TokenCalculator,
    tool_compressor: Optional[ToolMessageCompressor],
    system_tokens: int,
    summary_token_budget: int,
    recent_token_budget: int
) -> List[BaseMessage]:
    """
    构建优化的上下文
    
    结构: [System] + [Summary] + [Recent Messages]
    """
    optimized = []
    
    # 1. System Prompt
    system_msg = build_system_message(user, active_tool_names, current_time)
    optimized.append(system_msg)
    
    # 2. 历史总结（如果有）
    if summary_metadata and summary_metadata.get('summary'):
        summary_text = summary_metadata['summary']
        summary_msg = SystemMessage(content=f"【对话历史总结】\n{summary_text}")
        optimized.append(summary_msg)
        
        summarized_until = summary_metadata.get('summarized_until', 0)
        recent_messages = messages[summarized_until:]
    else:
        recent_messages = messages
    
    # 3. 压缩工具消息
    if tool_compressor:
        recent_messages = [
            tool_compressor.compress(msg, token_calculator) if isinstance(msg, ToolMessage) else msg
            for msg in recent_messages
        ]
    
    # 4. 从后往前选择最近对话（直到达到 Token 预算）
    selected_messages = []
    cumulative_tokens = 0
    available_tokens = recent_token_budget
    
    for msg in reversed(recent_messages):
        msg_tokens = token_calculator.calculate_message(msg)
        
        if cumulative_tokens + msg_tokens > available_tokens:
            # 超出预算，停止添加
            break
        
        selected_messages.insert(0, msg)
        cumulative_tokens += msg_tokens
    
    optimized.extend(selected_messages)
    
    # 日志
    total_tokens = system_tokens + (summary_metadata.get('summary_tokens', 0) if summary_metadata else 0) + cumulative_tokens
    logger.info(
        f"[优化] 上下文构建完成: "
        f"System={system_tokens}t, "
        f"Summary={summary_metadata.get('summary_tokens', 0) if summary_metadata else 0}t, "
        f"Recent={cumulative_tokens}t ({len(selected_messages)}条/{len(recent_messages)}条), "
        f"Total={total_tokens}t"
    )
    
    return optimized


def build_full_context(
    user,
    active_tool_names: List[str],
    current_time: str,
    messages: List[BaseMessage]
) -> List[BaseMessage]:
    """构建完整上下文（不优化）"""
    system_msg = build_system_message(user, active_tool_names, current_time)
    return [system_msg] + messages

        system_prompt = build_system_prompt(user, active_tool_names, current_time)
        optimized_messages = [SystemMessage(content=system_prompt)] + messages
    
    # ===== 5. 调用 LLM =====
    tools = get_tools_by_names(active_tool_names)
    
    if tools:
        llm_with_tools = llm.bind_tools(tools)
    else:
        llm_with_tools = llm
    
    response = llm_with_tools.invoke(optimized_messages)
    
    # ===== 6. 记录 Token 使用 =====
    try:
        usage = response.response_metadata.get('usage', {})
        prompt_tokens = usage.get('prompt_tokens', 0)
        completion_tokens = usage.get('completion_tokens', 0)
        
        if prompt_tokens > 0:
            logger.info(
                f"[Token使用] Prompt: {prompt_tokens}t, "
                f"Completion: {completion_tokens}t, "
                f"Total: {prompt_tokens + completion_tokens}t, "
                f"窗口使用率: {prompt_tokens / style.model_window_size:.1%}"
            )
    except Exception as e:
        logger.warning(f"[Token使用] 统计失败: {e}")
    
    # ===== 7. 返回结果（包含更新的总结元数据） =====
    return {
        "messages": [response],
        "summary_metadata": new_summary_metadata
    }


async def build_optimized_context(
    user,
    active_tool_names: List[str],
    current_time: str,
    messages: List[BaseMessage],
    summary_metadata: Optional[Dict],
    style,
    token_calculator,
    tool_compressor
) -> List[BaseMessage]:
    """
    构建优化后的上下文
    
    结构: [System] + [Summary (可选)] + [Recent Messages]
    """
    optimized = []
    
    # 1. System Prompt
    system_prompt = build_system_prompt(user, active_tool_names, current_time)
    system_msg = SystemMessage(content=system_prompt)
    optimized.append(system_msg)
    system_tokens = token_calculator.calculate_messages([system_msg])
    
    # 2. 历史总结（如果有）
    summary_tokens = 0
    recent_start_index = 0
    
    if summary_metadata:
        summary_text = summary_metadata.get('summary', '')
        if summary_text:
            summary_msg = SystemMessage(content=f"## 对话历史总结\n\n{summary_text}\n\n---")
            optimized.append(summary_msg)
            summary_tokens = summary_metadata.get('summary_tokens', 0)
            recent_start_index = summary_metadata.get('summarized_until', 0)
            
            logger.debug(f"[上下文] 添加历史总结: {summary_tokens}t, 截止第 {recent_start_index} 条")
    
    # 3. 最近对话（从后往前累加，直到达到 Token 预算）
    recent_messages = messages[recent_start_index:]
    
    # 计算可用 Token 预算
    response_budget = 4000  # 预留给 LLM 响应
    available_tokens = style.target_total_tokens - system_tokens - summary_tokens - response_budget
    
    if available_tokens < 0:
        logger.warning(f"[上下文] Token 预算不足: {available_tokens}")
        available_tokens = style.recent_token_budget
    
    # 从后往前选择消息
    selected_messages = []
    cumulative_tokens = 0
    
    for msg in reversed(recent_messages):
        # 压缩工具输出
        if style.compress_tool_output and isinstance(msg, ToolMessage):
            msg = tool_compressor.compress(msg, token_calculator)
        
        msg_tokens = token_calculator.calculate_messages([msg])
        
        if cumulative_tokens + msg_tokens > available_tokens:
            logger.debug(f"[上下文] 达到预算限制，停止添加消息")
            break
        
        selected_messages.insert(0, msg)
        cumulative_tokens += msg_tokens
    
    optimized.extend(selected_messages)
    
    # 统计
    total_tokens = system_tokens + summary_tokens + cumulative_tokens
    logger.info(
        f"[上下文构建] System: {system_tokens}t, "
        f"Summary: {summary_tokens}t, "
        f"Recent: {cumulative_tokens}t ({len(selected_messages)}条), "
        f"总计: {total_tokens}t / {style.target_total_tokens}t "
        f"({total_tokens / style.target_total_tokens:.1%})"
    )
    
    return optimized
```

```python
class DialogStyle(models.Model):
    # ... 现有字段 ...
    
    # ===== 上下文优化配置 =====
    enable_context_optimization = models.BooleanField(
        default=True,
        verbose_name="启用上下文优化",
        help_text="是否在发送给 LLM 前优化消息列表以减少 Token 消耗"
    )
    
    max_context_messages = models.IntegerField(
        default=20,
        verbose_name="上下文窗口大小",
        help_text="保留的最大消息数（不含 SystemMessage），超过部分会被截断"
    )
    
    compress_tool_output = models.BooleanField(
        default=True,
        verbose_name="压缩工具输出",
        help_text="是否压缩工具调用的返回内容"
    )
    
    tool_output_max_length = models.IntegerField(
        default=500,
        verbose_name="工具输出最大长度",
        help_text="工具输出压缩后的最大字符数"
    )
    
    class Meta:
        verbose_name = "对话风格"
        verbose_name_plural = "对话风格"
```

### Step 7: 创建前端 API - 模型配置和 Token 统计

**文件**: `core/views.py`

```python
from django.http import JsonResponse
from django.views.decorators.http import require_http_methods
from django.contrib.auth.decorators import login_required
import json
import os

@login_required
@require_http_methods(["GET"])
def get_model_config(request):
    """获取用户的模型配置"""
    try:
        user_data = request.user.user_data
        config = user_data.agent_model_config or {}
        
        # 获取系统预置模型列表
        system_models = get_system_models()
        
        # 合并用户自定义模型
        models = config.get('models', {})
        all_models = {**system_models, **{k: v for k, v in models.items() if v.get('provider') == 'custom'}}
        
        current_model_id = config.get('current_model_id', 'system_deepseek')
        
        return JsonResponse({
            'success': True,
            'current_model_id': current_model_id,
            'models': all_models,
            'optimization_config': user_data.get_optimization_config()
        })
    except Exception as e:
        return JsonResponse({'success': False, 'error': str(e)}, status=400)


@login_required
@require_http_methods(["POST"])
def update_model_config(request):
    """更新模型配置"""
    try:
        data = json.loads(request.body)
        user_data = request.user.user_data
        
        action = data.get('action')
        
        if action == 'select_model':
            # 切换当前模型
            model_id = data.get('model_id')
            config = user_data.agent_model_config or {}
            config['current_model_id'] = model_id
            user_data.agent_model_config = config
            user_data.save()
            
        elif action == 'add_custom_model':
            # 添加自定义模型
            model_data = data.get('model')
            model_id = f"custom_{len(user_data.agent_model_config.get('models', {}))}"
            
            config = user_data.agent_model_config or {}
            if 'models' not in config:
                config['models'] = {}
            
            config['models'][model_id] = {
                'name': model_data['name'],
                'provider': 'custom',
                'api_url': model_data['api_url'],
                'api_key': model_data['api_key'],  # 注意：生产环境应加密存储
                'context_window': model_data['context_window'],
                'supports_tools': model_data.get('supports_tools', True),
                'cost_per_1k_input': model_data.get('cost_per_1k_input', 0),
                'cost_per_1k_output': model_data.get('cost_per_1k_output', 0),
            }
            
            user_data.agent_model_config = config
            user_data.save()
            
            return JsonResponse({'success': True, 'model_id': model_id})
            
        elif action == 'delete_custom_model':
            # 删除自定义模型
            model_id = data.get('model_id')
            config = user_data.agent_model_config or {}
            
            if model_id in config.get('models', {}):
                del config['models'][model_id]
                
                # 如果删除的是当前模型，切换回默认
                if config.get('current_model_id') == model_id:
                    config['current_model_id'] = 'system_deepseek'
                
                user_data.agent_model_config = config
                user_data.save()
        
        elif action == 'update_optimization':
            # 更新优化配置
            opt_config = data.get('optimization_config')
            user_data.context_optimization_config = opt_config
            user_data.save()
        
        return JsonResponse({'success': True})
        
    except Exception as e:
        return JsonResponse({'success': False, 'error': str(e)}, status=400)


@login_required
@require_http_methods(["GET"])
def get_token_usage(request):
    """获取 Token 使用统计"""
    try:
        user_data = request.user.user_data
        stats = user_data.token_usage_stats or {}
        
        # 获取查询参数
        period = request.GET.get('period', 'all')  # all, today, week, month
        
        if period == 'today':
            from datetime import datetime
            today = datetime.now().strftime('%Y-%m-%d')
            daily_stats = stats.get('daily_stats', {})
            data = daily_stats.get(today, {'input_tokens': 0, 'output_tokens': 0, 'cost': 0})
        elif period == 'week':
            # 计算最近 7 天
            from datetime import datetime, timedelta
            daily_stats = stats.get('daily_stats', {})
            data = {'input_tokens': 0, 'output_tokens': 0, 'cost': 0}
            for i in range(7):
                date = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
                day_data = daily_stats.get(date, {})
                data['input_tokens'] += day_data.get('input_tokens', 0)
                data['output_tokens'] += day_data.get('output_tokens', 0)
                data['cost'] += day_data.get('cost', 0)
        else:
            # 全部统计
            data = {
                'input_tokens': stats.get('total_input_tokens', 0),
                'output_tokens': stats.get('total_output_tokens', 0),
                'cost': stats.get('total_cost', 0),
                'quota': stats.get('quota', 9999999),
            }
        
        # 添加模型统计
        data['model_stats'] = stats.get('model_stats', {})
        data['daily_stats'] = stats.get('daily_stats', {})
        
        return JsonResponse({
            'success': True,
            'usage': data
        })
        
    except Exception as e:
        return JsonResponse({'success': False, 'error': str(e)}, status=400)


def get_system_models():
    """获取系统预置模型列表"""
    from django.conf import settings
    
    return {
        'system_deepseek': {
            'name': 'DeepSeek Chat（系统提供）',
            'provider': 'system',
            'api_url': 'https://api.deepseek.com/v1/chat/completions',
            'api_key': '由系统管理',
            'context_window': 128000,
            'supports_tools': True,
            'cost_per_1k_input': 0.00014,
            'cost_per_1k_output': 0.00028,
            'readonly': True,  # 系统模型不可编辑
        },
        # 可以添加更多系统预置模型
        # 'system_gpt4': {...},
        # 'system_claude': {...},
    }
```

**文件**: `core/urls.py`

```python
from django.urls import path
from . import views

urlpatterns = [
    # ... 现有路由 ...
    
    # Agent 模型配置 API
    path('api/agent/model-config/', views.get_model_config, name='get_model_config'),
    path('api/agent/model-config/update/', views.update_model_config, name='update_model_config'),
    
    # Token 使用统计 API
    path('api/agent/token-usage/', views.get_token_usage, name='get_token_usage'),
]
```

### Step 8: 前端界面设计 - AI 设置页面

**文件**: `core/templates/settings.html` 或 `core/templates/ai_settings.html`

添加以下内容到现有的"设置 - AI设置"页面：

```html
<!-- Agent 模型配置区域 -->
<div class="settings-section">
    <h3>Agent 模型配置</h3>
    
    <!-- 当前模型显示 -->
    <div class="current-model-card">
        <h4>当前使用模型</h4>
        <div id="current-model-info">
            <p><strong>名称:</strong> <span id="model-name">加载中...</span></p>
            <p><strong>上下文窗口:</strong> <span id="model-window">-</span> tokens</p>
            <p><strong>类型:</strong> <span id="model-provider">-</span></p>
        </div>
        <button onclick="showModelSelector()" class="btn btn-primary">切换模型</button>
    </div>
    
    <!-- 模型选择器（模态框）-->
    <div id="model-selector-modal" class="modal" style="display: none;">
        <div class="modal-content">
            <h4>选择模型</h4>
            
            <!-- 系统模型 -->
            <div class="model-group">
                <h5>系统提供的模型</h5>
                <div id="system-models-list">
                    <!-- 动态生成 -->
                </div>
            </div>
            
            <!-- 自定义模型 -->
            <div class="model-group">
                <h5>我的自定义模型</h5>
                <div id="custom-models-list">
                    <!-- 动态生成 -->
                </div>
                <button onclick="showAddCustomModel()" class="btn btn-secondary">+ 添加自定义模型</button>
            </div>
            
            <button onclick="closeModelSelector()" class="btn">取消</button>
        </div>
    </div>
    
    <!-- 添加自定义模型表单 -->
    <div id="add-custom-model-modal" class="modal" style="display: none;">
        <div class="modal-content">
            <h4>添加自定义模型</h4>
            <form id="custom-model-form">
                <label>模型名称:</label>
                <input type="text" name="name" required placeholder="例如: 我的 GPT-4">
                
                <label>API URL:</label>
                <input type="url" name="api_url" required placeholder="https://api.example.com/v1/chat/completions">
                
                <label>API Key:</label>
                <input type="password" name="api_key" required placeholder="sk-...">
                
                <label>上下文窗口 (tokens):</label>
                <input type="number" name="context_window" required value="128000">
                
                <label>输入价格 ($/1K tokens):</label>
                <input type="number" name="cost_per_1k_input" step="0.00001" value="0">
                
                <label>输出价格 ($/1K tokens):</label>
                <input type="number" name="cost_per_1k_output" step="0.00001" value="0">
                
                <div class="form-actions">
                    <button type="submit" class="btn btn-primary">添加</button>
                    <button type="button" onclick="closeAddCustomModel()" class="btn">取消</button>
                </div>
            </form>
        </div>
    </div>
</div>

<!-- Token 使用统计区域 -->
<div class="settings-section">
    <h3>Token 使用统计</h3>
    
    <div class="token-stats-tabs">
        <button onclick="loadTokenStats('today')" class="tab-btn active">今天</button>
        <button onclick="loadTokenStats('week')" class="tab-btn">最近 7 天</button>
        <button onclick="loadTokenStats('all')" class="tab-btn">全部</button>
    </div>
    
    <div class="token-stats-content">
        <div class="stat-card">
            <h4>输入 Tokens</h4>
            <p class="stat-value" id="input-tokens">-</p>
        </div>
        <div class="stat-card">
            <h4>输出 Tokens</h4>
            <p class="stat-value" id="output-tokens">-</p>
        </div>
        <div class="stat-card">
            <h4>总费用</h4>
            <p class="stat-value" id="total-cost">$0.00</p>
        </div>
        <div class="stat-card">
            <h4>剩余额度</h4>
            <p class="stat-value" id="remaining-quota">-</p>
        </div>
    </div>
    
    <!-- 按模型统计 -->
    <div class="model-stats">
        <h4>各模型使用情况</h4>
        <table id="model-stats-table">
            <thead>
                <tr>
                    <th>模型</th>
                    <th>输入</th>
                    <th>输出</th>
                    <th>费用</th>
                </tr>
            </thead>
            <tbody>
                <!-- 动态生成 -->
            </tbody>
        </table>
    </div>
</div>

<!-- 上下文优化配置区域 -->
<div class="settings-section">
    <h3>上下文优化配置</h3>
    
    <form id="optimization-config-form">
        <div class="form-group">
            <label>
                <input type="checkbox" name="enable_optimization" checked>
                启用上下文优化
            </label>
        </div>
        
        <div class="form-group">
            <label>目标窗口使用率:</label>
            <input type="range" name="target_usage_ratio" min="0.4" max="0.8" step="0.05" value="0.6">
            <span id="target-ratio-display">60%</span>
        </div>
        
        <div class="form-group">
            <label>
                <input type="checkbox" name="enable_summarization" checked>
                启用智能总结
            </label>
        </div>
        
        <div class="form-group">
            <label>
                <input type="checkbox" name="compress_tool_output" checked>
                压缩工具输出
            </label>
        </div>
        
        <button type="submit" class="btn btn-primary">保存配置</button>
    </form>
</div>

<script>
// JavaScript 代码
let currentConfig = null;

// 加载配置
async function loadModelConfig() {
    try {
        const response = await fetch('/api/agent/model-config/');
        const data = await response.json();
        
        if (data.success) {
            currentConfig = data;
            updateCurrentModelDisplay(data);
            updateOptimizationForm(data.optimization_config);
        }
    } catch (error) {
        console.error('加载配置失败:', error);
    }
}

// 更新当前模型显示
function updateCurrentModelDisplay(data) {
    const currentModel = data.models[data.current_model_id];
    document.getElementById('model-name').textContent = currentModel.name;
    document.getElementById('model-window').textContent = currentModel.context_window.toLocaleString();
    document.getElementById('model-provider').textContent = currentModel.provider === 'system' ? '系统提供' : '自定义';
}

// 显示模型选择器
function showModelSelector() {
    const modal = document.getElementById('model-selector-modal');
    
    // 填充系统模型
    const systemList = document.getElementById('system-models-list');
    systemList.innerHTML = '';
    Object.entries(currentConfig.models).forEach(([id, model]) => {
        if (model.provider === 'system') {
            systemList.innerHTML += createModelCard(id, model);
        }
    });
    
    // 填充自定义模型
    const customList = document.getElementById('custom-models-list');
    customList.innerHTML = '';
    Object.entries(currentConfig.models).forEach(([id, model]) => {
        if (model.provider === 'custom') {
            customList.innerHTML += createModelCard(id, model, true);
        }
    });
    
    modal.style.display = 'block';
}

// 创建模型卡片 HTML
function createModelCard(id, model, canDelete = false) {
    const isActive = id === currentConfig.current_model_id;
    return `
        <div class="model-card ${isActive ? 'active' : ''}" onclick="selectModel('${id}')">
            <h6>${model.name}</h6>
            <p>窗口: ${model.context_window.toLocaleString()} tokens</p>
            ${canDelete ? `<button onclick="deleteModel('${id}', event)" class="btn-delete">删除</button>` : ''}
        </div>
    `;
}

// 选择模型
async function selectModel(modelId) {
    try {
        const response = await fetch('/api/agent/model-config/update/', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({action: 'select_model', model_id: modelId})
        });
        
        if (response.ok) {
            await loadModelConfig();
            closeModelSelector();
            alert('模型切换成功！');
        }
    } catch (error) {
        console.error('切换模型失败:', error);
    }
}

// 添加自定义模型表单提交
document.getElementById('custom-model-form').addEventListener('submit', async (e) => {
    e.preventDefault();
    const formData = new FormData(e.target);
    const modelData = Object.fromEntries(formData);
    
    try {
        const response = await fetch('/api/agent/model-config/update/', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({action: 'add_custom_model', model: modelData})
        });
        
        if (response.ok) {
            await loadModelConfig();
            closeAddCustomModel();
            alert('自定义模型添加成功！');
        }
    } catch (error) {
        console.error('添加模型失败:', error);
    }
});

// 加载 Token 统计
async function loadTokenStats(period = 'all') {
    try {
        const response = await fetch(`/api/agent/token-usage/?period=${period}`);
        const data = await response.json();
        
        if (data.success) {
            const usage = data.usage;
            document.getElementById('input-tokens').textContent = usage.input_tokens.toLocaleString();
            document.getElementById('output-tokens').textContent = usage.output_tokens.toLocaleString();
            document.getElementById('total-cost').textContent = `$${usage.cost.toFixed(4)}`;
            
            if (period === 'all') {
                const remaining = usage.quota - usage.input_tokens - usage.output_tokens;
                document.getElementById('remaining-quota').textContent = remaining.toLocaleString();
            }
            
            // 更新模型统计表
            updateModelStatsTable(usage.model_stats);
        }
    } catch (error) {
        console.error('加载统计失败:', error);
    }
}

// 更新模型统计表
function updateModelStatsTable(modelStats) {
    const tbody = document.querySelector('#model-stats-table tbody');
    tbody.innerHTML = '';
    
    Object.entries(modelStats).forEach(([modelId, stats]) => {
        const modelName = currentConfig.models[modelId]?.name || modelId;
        tbody.innerHTML += `
            <tr>
                <td>${modelName}</td>
                <td>${stats.input_tokens.toLocaleString()}</td>
                <td>${stats.output_tokens.toLocaleString()}</td>
                <td>$${stats.cost.toFixed(4)}</td>
            </tr>
        `;
    });
}

// 页面加载时初始化
document.addEventListener('DOMContentLoaded', () => {
    loadModelConfig();
    loadTokenStats('all');
});
</script>

<style>
.settings-section {
    margin-bottom: 30px;
    padding: 20px;
    background: #f9f9f9;
    border-radius: 8px;
}

.current-model-card {
    background: white;
    padding: 15px;
    border-radius: 5px;
    margin-bottom: 15px;
}

.model-card {
    background: white;
    padding: 10px;
    margin: 10px 0;
    border: 2px solid #ddd;
    border-radius: 5px;
    cursor: pointer;
}

.model-card.active {
    border-color: #007bff;
    background: #e7f3ff;
}

.token-stats-content {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 15px;
    margin-top: 15px;
}

.stat-card {
    background: white;
    padding: 15px;
    border-radius: 5px;
    text-align: center;
}

.stat-value {
    font-size: 24px;
    font-weight: bold;
    color: #007bff;
}
</style>
```

### Step 9: 创建数据库迁移

```bash
# Agent Service 迁移（简化 DialogStyle）
python manage.py makemigrations agent_service --name simplify_dialog_style_optimization

# Core 迁移（添加模型配置和 Token 统计）
python manage.py makemigrations core --name add_agent_config_and_token_stats

# 执行迁移
python manage.py migrate
```

## 3. 测试方案

### 3.1 单元测试

**文件**: `agent_service/tests/test_token_optimization.py`

```python
import pytest
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage
from agent_service.context_optimizer import TokenCalculator, ToolMessageCompressor


class TestTokenCalculator:
    
    def test_estimate_method(self):
        """测试粗略估算"""
        calculator = TokenCalculator(method="estimate")
        
        messages = [
            HumanMessage(content="Hello, how are you?"),
            AIMessage(content="I'm fine, thank you!")
        ]
        
        tokens = calculator.calculate_messages(messages)
        assert 10 <= tokens <= 20  # 粗略范围
    
    def test_actual_method_with_metadata(self):
        """测试使用实际统计"""
        calculator = TokenCalculator(method="actual")
        
        messages = [HumanMessage(content="test")]
        usage = {'prompt_tokens': 100, 'completion_tokens': 50}
        
        tokens = calculator.calculate_messages(messages, usage)
        assert tokens == 100
    
    def test_calculate_text(self):
        """测试文本 Token 计算"""
        calculator = TokenCalculator(method="estimate")
        
        text = "Hello world! " * 100  # ~1200 字符
        tokens = calculator.calculate_text(text)
        assert 400 <= tokens <= 600  # 约 480 tokens


class TestToolMessageCompressor:
    
    def test_compress_json_search_result(self):
        """测试压缩搜索结果"""
        compressor = ToolMessageCompressor(max_tokens=100)
        calculator = TokenCalculator(method="estimate")
        
        long_json = '{"items": [' + ','.join([
            '{"search_index": %d, "title": "Item %d", "type": "event"}' % (i, i)
            for i in range(50)
        ]) + ']}'
        
        msg = ToolMessage(content=long_json, tool_call_id="call_123", name="search_items")
        compressed = compressor.compress(msg, calculator)
        
        # 应该被压缩
        assert len(compressed.content) < len(long_json)
        assert "查询成功" in compressed.content or "..." in compressed.content
    
    def test_no_compression_needed(self):
        """测试短内容不需要压缩"""
        compressor = ToolMessageCompressor(max_tokens=200)
        calculator = TokenCalculator(method="estimate")
        
        short_content = '{"success": true, "message": "OK"}'
        msg = ToolMessage(content=short_content, tool_call_id="call_123", name="test")
        
        compressed = compressor.compress(msg, calculator)
        assert compressed.content == short_content


@pytest.mark.asyncio
class TestConversationSummarizer:
    
    async def test_should_summarize_first_time(self):
        """测试首次总结判断"""
        from agent_service.context_summarizer import ConversationSummarizer
        
        # Mock LLM
        class MockLLM:
            pass
        
        calculator = TokenCalculator(method="estimate")
        summarizer = ConversationSummarizer(
            llm=MockLLM(),
            token_calculator=calculator,
            min_messages=10
        )
        
        # 消息数不足
        messages = [HumanMessage(content=f"Message {i}") for i in range(5)]
        assert not summarizer.should_summarize(messages, None)
        
        # 消息数足够
        messages = [HumanMessage(content=f"Message {i}") for i in range(20)]
        assert summarizer.should_summarize(messages, None)
    
    async def test_should_summarize_with_new_messages(self):
        """测试新消息触发总结"""
        from agent_service.context_summarizer import ConversationSummarizer
        
        calculator = TokenCalculator(method="estimate")
        summarizer = ConversationSummarizer(
            llm=None,
            token_calculator=calculator,
            trigger_ratio=0.5
        )
        
        messages = [HumanMessage(content=f"Message {i}") for i in range(100)]
        
        # 假设已总结到 60 条，总结 Token 为 5000
        summary_meta = {
            'summarized_until': 60,
            'summary_tokens': 5000
        }
        
        # 新增 40 条消息，Token 约 2000，比例 40% < 50%，不触发
        should = summarizer.should_summarize(messages[:60], summary_meta)
        assert not should
        
        # 新增更多消息，Token 超过 2500，比例 > 50%，触发
        should = summarizer.should_summarize(messages, summary_meta)
        # 这里需要实际计算，可能触发
```

### 3.2 集成测试

创建一个长对话会话，验证：

```python
# tests/test_integration_context_optimization.py

@pytest.mark.django_db
@pytest.mark.asyncio
async def test_long_conversation_with_optimization():
    """测试长对话的完整优化流程"""
    from django.contrib.auth import get_user_model
    from agent_service.models import DialogStyle, AgentSession
    from agent_service.agent_graph import app
    
    User = get_user_model()
    user = User.objects.create_user(username='test', password='test')
    
    # 配置优化参数
    style = DialogStyle.get_or_create_default(user)
    style.enable_context_optimization = True
    style.enable_summarization = True
    style.model_window_size = 10000  # 小窗口用于测试
    style.target_usage_ratio = 0.6
    style.min_messages_before_summary = 10
    style.save()
    
    # 创建会话
    session_id = f"test_{user.id}_123"
    config = {
        "configurable": {
            "thread_id": session_id,
            "user": user,
            "active_tools": ["search_items", "create_item"]
        }
    }
    
    # 模拟 30 轮对话
    for i in range(30):
        input_state = {
            "messages": [HumanMessage(content=f"测试消息 {i+1}: 创建一个日程")]
        }
        
        # 执行
        result = await app.ainvoke(input_state, config)
        
        # 验证
        state = app.get_state(config)
        messages = state.values.get("messages", [])
        summary_meta = state.values.get("summary_metadata")
        
        print(f"Round {i+1}: {len(messages)} messages, Summary: {summary_meta is not None}")
        
        # 第 10 轮后应该有总结
        if i >= 10:
            assert summary_meta is not None
            assert summary_meta.get('summary_tokens') > 0
    
    # 最终验证
    final_state = app.get_state(config)
    final_messages = final_state.values.get("messages", [])
    final_summary = final_state.values.get("summary_metadata")
    
    assert final_summary is not None
    assert final_summary['summarized_until'] > 10
    assert len(final_messages) < 60  # 总消息数应该被控制
```

### 3.3 性能测试

```python
import time

def test_optimization_performance():
    """测试优化性能"""
    from agent_service.context_optimizer import TokenCalculator
    
    calculator = TokenCalculator(method="estimate")
    
    # 创建大量消息
    messages = [
        HumanMessage(content=f"Message {i}" * 100)
        for i in range(1000)
    ]
    
    # 测试计算时间
    start = time.time()
    tokens = calculator.calculate_messages(messages)
    elapsed = time.time() - start
    
    assert elapsed < 1.0  # 应该在 1 秒内完成
    assert tokens > 0
    print(f"Calculated {tokens} tokens for {len(messages)} messages in {elapsed:.3f}s")
```

### Step 4: 集成到 agent_node

**文件**: `agent_service/agent_graph.py`

在 `agent_node` 函数中添加优化逻辑：

```python
def agent_node(state: AgentState, config: RunnableConfig) -> dict:
    """
    统一的 Agent 节点，根据 active_tools 动态绑定工具
    """
    messages = state['messages']
    
    # 优先从 config 获取配置
    configurable = config.get("configurable", {})
    active_tool_names = configurable.get("active_tools") or state.get('active_tools') or get_default_tools()
    user = configurable.get("user")
    
    # ... 现有日志代码 ...
    
    # 获取当前时间
    now = datetime.datetime.now()
    current_time = now.strftime("%Y-%m-%d %H:%M:%S")
    
    # 构建 system prompt
    system_prompt = build_system_prompt(user, active_tool_names, current_time)
    system_message = SystemMessage(content=system_prompt)
    
    # 完整消息列表（用于 LLM）
    full_messages = [system_message] + messages
    
    # ===== 新增: 上下文优化 =====
    # 1. 加载用户的优化配置
    from agent_service.models import DialogStyle
    from agent_service.context_optimizer import ContextOptimizer
    
    enable_optimization = True
    max_messages = 20
    compress_tool = True
    tool_max_length = 500
    
    try:
        if user and user.is_authenticated:
            style = DialogStyle.get_or_create_default(user)
            enable_optimization = style.enable_context_optimization
            max_messages = style.max_context_messages
            compress_tool = style.compress_tool_output
            tool_max_length = style.tool_output_max_length
    except Exception as e:
        logger.warning(f"[Agent] 加载优化配置失败，使用默认值: {e}")
    
    # 2. 应用优化
    if enable_optimization:
        optimizer = ContextOptimizer(
            max_messages=max_messages,
            compress_tool_output=compress_tool,
            tool_output_max_length=tool_max_length,
            enable_logging=True
        )
        
        # 估算优化前的 Token
        before_tokens = optimizer.estimate_tokens(full_messages)
        
        # 执行优化
        optimized_messages = optimizer.optimize(full_messages)
        
        # 估算优化后的 Token
        after_tokens = optimizer.estimate_tokens(optimized_messages)
        
        # 记录优化效果
        if before_tokens > 0:
            savings = (1 - after_tokens / before_tokens) * 100
            logger.info(
                f"[上下文优化] Token估算: {before_tokens} → {after_tokens}, "
                f"节省: {savings:.1f}%"
            )
        
        messages_to_llm = optimized_messages
    else:
        logger.debug("[上下文优化] 已禁用，使用完整历史")
        messages_to_llm = full_messages
    # ================================
    
    # 动态获取工具
    tools = get_tools_by_names(active_tool_names)
    
    # ... 现有工具绑定代码 ...
    
    if tools:
        llm_with_tools = llm.bind_tools(tools)
    else:
        llm_with_tools = llm
    
    # 使用优化后的消息调用 LLM
    response = llm_with_tools.invoke(messages_to_llm)
    
    return {"messages": [response]}
```

### Step 5: 添加管理界面配置

**文件**: `agent_service/admin.py`

```python
from django.contrib import admin
from .models import DialogStyle

@admin.register(DialogStyle)
class DialogStyleAdmin(admin.ModelAdmin):
    list_display = ['user', 'enable_context_optimization', 'max_context_messages', 'compress_tool_output']
    list_filter = ['enable_context_optimization', 'compress_tool_output']
    search_fields = ['user__username']
    
    fieldsets = (
        ('基本信息', {
            'fields': ('user', 'content', 'memory_batch_size')
        }),
        ('上下文优化', {
            'fields': (
                'enable_context_optimization',
                'max_context_messages',
                'compress_tool_output',
                'tool_output_max_length'
            ),
            'description': '控制 Agent 如何优化消息历史以减少 Token 消耗'
        }),
    )
```

## 3. 测试方案

### 3.1 单元测试

**文件**: `agent_service/tests/test_context_optimizer.py`

```python
import pytest
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from agent_service.context_optimizer import ContextOptimizer


class TestContextOptimizer:
    
    def test_sliding_window_basic(self):
        """测试基本的滑动窗口功能"""
        optimizer = ContextOptimizer(max_messages=5)
        
        messages = [
            SystemMessage(content="System"),
            HumanMessage(content="1"),
            AIMessage(content="2"),
            HumanMessage(content="3"),
            AIMessage(content="4"),
            HumanMessage(content="5"),
            AIMessage(content="6"),
            HumanMessage(content="7"),
            AIMessage(content="8"),
        ]
        
        optimized = optimizer.optimize(messages)
        
        # SystemMessage + 最近5条
        assert len(optimized) == 6
        assert isinstance(optimized[0], SystemMessage)
        assert optimized[-1].content == "8"
    
    def test_tool_message_compression(self):
        """测试工具输出压缩"""
        optimizer = ContextOptimizer(compress_tool_output=True)
        
        long_content = '{"items": [' + ','.join(['{"id": "xxx", "title": "item"}'] * 50) + ']}'
        
        messages = [
            ToolMessage(content=long_content, tool_call_id="call_123", name="search_items")
        ]
        
        optimized = optimizer.optimize(messages)
        
        # 应该被压缩
        assert len(optimized[0].content) < len(long_content)
        assert "查询成功" in optimized[0].content or "..." in optimized[0].content
    
    def test_token_estimation(self):
        """测试 Token 估算"""
        optimizer = ContextOptimizer()
        
        messages = [
            HumanMessage(content="Hello, how are you?"),  # ~5 tokens
            AIMessage(content="I'm fine, thank you!")     # ~5 tokens
        ]
        
        tokens = optimizer.estimate_tokens(messages)
        
        # 粗略估算应该在合理范围
        assert 8 <= tokens <= 15
```

### 3.2 集成测试

创建一个长对话会话，验证：
1. 消息数 < 20 时不触发优化
2. 消息数 > 20 时自动截断
3. 工具输出被正确压缩
4. AI 回复质量不下降

### 3.3 性能测试

测量：
- 优化耗时（应 < 50ms）
- Token 节省率（目标 40-60%）
- LLM 响应时间变化

## 4. 部署检查清单

- [ ] 代码审查通过
- [ ] 单元测试通过
- [ ] 集成测试通过
- [ ] 数据库迁移执行成功
- [ ] 日志输出正常
- [ ] 配置项可通过 Admin 修改
- [ ] 文档更新

## 4. 部署检查清单

### 4.1 部署前检查

- [ ] **依赖安装**
  ```bash
  pip install tiktoken  # 可选，用于精确 Token 计算
  ```

- [ ] **数据库迁移**
  ```bash
  python manage.py makemigrations agent_service
  python manage.py migrate
  ```

- [ ] **配置验证**
  - 检查 `DialogStyle` 默认值是否合理
  - 验证 `model_window_size` 与实际使用的模型匹配
  - 确认 `target_usage_ratio` 不超过 0.8

- [ ] **日志配置**
  ```python
  # settings.py
  LOGGING = {
      'loggers': {
          'agent_service.context_optimizer': {
              'level': 'INFO',  # 生产环境用 WARNING
              'handlers': ['file'],
          },
          'agent_service.context_summarizer': {
              'level': 'INFO',
              'handlers': ['file'],
          },
      }
  }
  ```

### 4.2 灰度发布策略

1. **阶段 1: 仅启用工具压缩** (1-2 天)
   - `enable_context_optimization = True`
   - `compress_tool_output = True`
   - `enable_summarization = False`
   - 观察工具压缩效果和错误率

2. **阶段 2: 启用总结但高阈值** (3-5 天)
   - `enable_summarization = True`
   - `min_messages_before_summary = 50`  # 较高阈值
   - `summary_trigger_ratio = 0.8`  # 较宽松触发
   - 观察总结质量和用户反馈

3. **阶段 3: 正常参数** (持续监控)
   - 逐步降低阈值到目标值
   - `min_messages_before_summary = 20`
   - `summary_trigger_ratio = 0.5`

### 4.3 回滚方案

如果发现问题，可以快速回滚：

```python
# 方案 1: 数据库全局关闭
from agent_service.models import DialogStyle
DialogStyle.objects.all().update(
    enable_context_optimization=False,
    enable_summarization=False
)

# 方案 2: 仅关闭问题用户
DialogStyle.objects.filter(user__username__in=['user1', 'user2']).update(
    enable_context_optimization=False
)

# 方案 3: 降级到工具压缩模式
DialogStyle.objects.all().update(
    enable_summarization=False,
    compress_tool_output=True
)
```

## 5. 监控和调优

### 5.1 关键指标

在 Agent 响应中添加监控信息：

```python
# views_api.py

async def agent_execute(...):
    # ... 执行逻辑 ...
    
    # 获取最终状态
    state = app.get_state(config)
    
    # 提取监控指标
    monitoring = {
        'total_messages': len(state.values.get('messages', [])),
        'token_usage': {
            'total': actual_usage.get('total_tokens', 0),
            'prompt': actual_usage.get('prompt_tokens', 0),
            'completion': actual_usage.get('completion_tokens', 0),
        },
        'optimization': {
            'enabled': optimization_enabled,
            'summarized': summary_meta is not None,
            'summary_tokens': summary_meta.get('summary_tokens', 0) if summary_meta else 0,
            'compressed_messages': len([m for m in messages if 'compressed' in m.additional_kwargs]),
        },
        'window_usage': {
            'target_tokens': dialog_style.target_total_tokens,
            'actual_tokens': actual_usage.get('prompt_tokens', 0),
            'usage_ratio': actual_usage.get('prompt_tokens', 0) / dialog_style.target_total_tokens,
        }
    }
    
    # 记录到日志
    logger.info(f"Agent execution monitoring: {monitoring}")
    
    # 返回给前端（可选）
    return {
        'response': result,
        'monitoring': monitoring if settings.DEBUG else None
    }
```

### 5.2 性能指标

监控以下指标：

1. **Token 使用率**
   - 目标: 稳定在 60% ± 10%
   - 警告: > 80%
   - 危险: > 90%

2. **总结触发频率**
   - 正常: 每 20-30 条消息触发一次
   - 异常: 连续触发或长期不触发

3. **压缩率**
   - 工具消息: 目标压缩 50-70%
   - 历史总结: 目标压缩 70-85%

4. **响应时间**
   - 无总结: < 5s
   - 有总结: < 8s（总结调用额外时间）

### 5.3 告警规则

```python
# 可集成到监控系统

def check_optimization_health(monitoring):
    alerts = []
    
    # 检查 Token 使用率
    usage_ratio = monitoring['window_usage']['usage_ratio']
    if usage_ratio > 0.9:
        alerts.append({
            'level': 'CRITICAL',
            'message': f'Token 使用率过高: {usage_ratio:.1%}'
        })
    elif usage_ratio > 0.8:
        alerts.append({
            'level': 'WARNING',
            'message': f'Token 使用率偏高: {usage_ratio:.1%}'
        })
    
    # 检查总结效果
    if monitoring['optimization']['summarized']:
        summary_tokens = monitoring['optimization']['summary_tokens']
        total_tokens = monitoring['token_usage']['prompt']
        summary_ratio = summary_tokens / total_tokens
        
        if summary_ratio > 0.5:  # 总结占比过高
            alerts.append({
                'level': 'WARNING',
                'message': f'历史总结占比过高: {summary_ratio:.1%}'
            })
    
    return alerts
```

### 5.4 调优建议

根据监控结果调整参数：

| 现象 | 可能原因 | 调优方案 |
|------|---------|---------|
| Token 使用率 > 80% | 目标比例过高 | 降低 `target_usage_ratio` 到 0.5 |
| 频繁触发总结 | 触发阈值过低 | 提高 `summary_trigger_ratio` 到 0.6-0.7 |
| 总结质量差 | 总结预算不足 | 提高 `summary_token_ratio` 到 0.3-0.35 |
| 上下文不连贯 | 最近对话过少 | 提高 `recent_token_ratio` 到 0.7-0.75 |
| 工具结果不完整 | 压缩过度 | 提高 `tool_output_max_tokens` 到 300-500 |

## 6. 常见问题

### Q1: 总结后 Agent 表现变差？

**可能原因**:
- 总结丢失了关键上下文
- 总结预算不足，信息密度过高

**解决方案**:
```python
# 方案 1: 增加总结预算
style.summary_token_ratio = 0.35  # 从 0.26 提高到 0.35

# 方案 2: 提高触发阈值，减少总结频率
style.summary_trigger_ratio = 0.7  # 从 0.5 提高到 0.7

# 方案 3: 增加最近对话保留量
style.recent_token_ratio = 0.75  # 从 0.65 提高到 0.75
```

### Q2: Token 计算不准确？

**解决方案**:
```python
# 优先使用 actual 方法
style.token_calculation_method = 'actual'

# 如果需要精确计算，安装 tiktoken
pip install tiktoken
style.token_calculation_method = 'tiktoken'
```

### Q3: 工具结果被过度压缩导致信息丢失？

**解决方案**:
```python
# 方案 1: 提高工具输出预算
style.tool_output_max_tokens = 500  # 从 200 提高

# 方案 2: 关闭特定工具的压缩
# 在 ToolMessageCompressor 中添加白名单
compressor = ToolMessageCompressor(
    max_tokens=200,
    exclude_tools=['get_details', 'search_important']  # 不压缩这些工具
)
```

### Q4: 如何查看总结内容？

```python
# 在 Admin 中查看
from agent_service.models import AgentSession

session = AgentSession.objects.get(session_id='xxx')
checkpoint = session.get_latest_checkpoint()
summary_meta = checkpoint.state.get('summary_metadata')

if summary_meta:
    print("总结内容:", summary_meta['summary_text'])
    print("总结 Token:", summary_meta['summary_tokens'])
    print("已总结到第", summary_meta['summarized_until'], "条消息")
```

### Q5: 如何添加或切换模型？

**在前端 AI 设置页面**:
1. 点击"切换模型"按钮
2. 选择系统提供的模型，或点击"添加自定义模型"
3. 填写模型信息（名称、API URL、密钥、窗口大小等）
4. 保存后即可在模型列表中选择使用

**系统会自动**:
- 根据模型的 `context_window` 调整 Token 预算
- 使用模型的费率计算消耗费用
- 分别统计每个模型的使用情况

### Q6: Token 消耗如何计费？

```python
# 费用计算公式
input_cost = (input_tokens / 1000) * model['cost_per_1k_input']
output_cost = (output_tokens / 1000) * model['cost_per_1k_output']
total_cost = input_cost + output_cost

# 例如 DeepSeek:
# 输入: 10,000 tokens * $0.00014/1K = $0.0014
# 输出: 5,000 tokens * $0.00028/1K = $0.0014
# 总计: $0.0028
```

## 7. 附录

### 7.1 完整的配置参数参考（存储在 UserData）

**模型配置** (`agent_model_config`):
| 字段 | 类型 | 说明 |
|-----|------|------|
| `current_model_id` | string | 当前使用的模型 ID |
| `models[id].name` | string | 模型名称 |
| `models[id].provider` | string | system 或 custom |
| `models[id].api_url` | string | API 端点 |
| `models[id].api_key` | string | API 密钥 |
| `models[id].context_window` | int | 上下文窗口大小 |
| `models[id].cost_per_1k_input` | float | 输入价格（美元/1K tokens）|
| `models[id].cost_per_1k_output` | float | 输出价格（美元/1K tokens）|

**优化配置** (`context_optimization_config`):
| 参数 | 类型 | 默认值 | 说明 |
|-----|------|--------|------|
| `enable_optimization` | bool | True | 启用优化 |
| `target_usage_ratio` | float | 0.6 | 目标使用 60% 窗口 |
| `token_calculation_method` | str | 'actual' | Token 计算方法 |
| `summary_token_ratio` | float | 0.26 | 总结占总预算的 26% |
| `recent_token_ratio` | float | 0.65 | 最近对话占总预算的 65% |
| `enable_summarization` | bool | True | 启用智能总结 |
| `summary_trigger_ratio` | float | 0.5 | 新消息/总结 > 50% 时触发 |
| `min_messages_before_summary` | int | 20 | 至少 20 条消息才总结 |
| `compress_tool_output` | bool | True | 压缩工具输出 |
| `tool_output_max_tokens` | int | 200 | 工具输出最大 Token |

**Token 统计** (`token_usage_stats`):
| 字段 | 类型 | 说明 |
|-----|------|------|
| `total_input_tokens` | int | 累计输入 tokens |
| `total_output_tokens` | int | 累计输出 tokens |
| `total_cost` | float | 累计费用（美元）|
| `quota` | int | Token 额度（暂时 9999999）|
| `daily_stats[date]` | dict | 每日统计 |
| `model_stats[model_id]` | dict | 各模型统计 |

### 7.2 Token 预算分配示例

以 DeepSeek (128K 窗口) 为例:

```
模型窗口: 128,000 tokens
目标使用: 128,000 * 0.6 = 76,800 tokens

Token 分配:
├─ System Prompt: ~2,000 tokens (固定)
├─ 历史总结: 76,800 * 0.26 = 19,968 tokens
├─ 最近对话: 76,800 * 0.65 = 49,920 tokens
└─ 缓冲区: 76,800 - 2,000 - 19,968 - 49,920 = 4,912 tokens

总计: 76,800 tokens (60% 窗口)
```

### 7.3 总结触发逻辑示例

```
场景: 已有 50 条消息，历史总结 15,000 tokens

1. 新增 10 条消息 (约 5,000 tokens)
   比例 = 5,000 / 15,000 = 33% < 50%
   → 不触发总结

2. 新增 20 条消息 (约 10,000 tokens)
   比例 = 10,000 / 15,000 = 67% > 50%
   → 触发总结

3. 重新总结前 70 条消息
   新总结 = 20,000 tokens
   已总结到第 70 条

4. 继续累积新消息...
```

---

## 实施完成标志

✅ 完成以下所有检查项后，上下文优化即可投入生产使用:

- [ ] 所有代码文件已创建
  - [ ] `agent_service/context_optimizer.py`
  - [ ] `agent_service/context_summarizer.py`
  - [ ] 修改 `core/models.py`（添加 UserData 字段）
  - [ ] 修改 `agent_service/models.py`（简化 DialogStyle）
  - [ ] 修改 `agent_service/agent_graph.py`（集成优化逻辑）
  - [ ] 修改 `core/views.py`（添加 API）
  - [ ] 修改前端 AI 设置页面

- [ ] 数据库迁移已执行
  - [ ] Core 迁移（UserData 字段）
  - [ ] Agent Service 迁移（DialogStyle 简化）

- [ ] 测试验证
  - [ ] 单元测试全部通过
  - [ ] 集成测试验证成功
  - [ ] 性能测试满足要求

- [ ] 前端界面完成
  - [ ] 模型选择和管理
  - [ ] Token 统计显示
  - [ ] 优化配置界面

- [ ] 运维配置
  - [ ] 日志和监控已部署
  - [ ] 灰度发布计划已执行
  - [ ] 用户文档已更新

**预期收益**:
- ✅ Token 使用降低 40-70%
- ✅ 支持更长的对话历史
- ✅ 自动适应不同模型
- ✅ 更好的成本控制
- ✅ 用户可自定义模型
- ✅ 实时 Token 消耗统计
