"""
Agent WebSocket Consumer
å¤„ç†ä¸ Agent çš„å®æ—¶é€šä¿¡
"""

# ========== Agent é…ç½®å¸¸é‡ ==========
# Agent å•æ¬¡å¯¹è¯ä¸­å…è®¸çš„æœ€å¤§å›¾æ‰§è¡Œæ­¥æ•° (recursion_limit)
# æ³¨æ„ï¼šè¿™ä¸æ˜¯å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼Œè€Œæ˜¯å›¾çš„æ‰§è¡Œæ­¥æ•°ï¼ˆåŒ…æ‹¬ LLM è°ƒç”¨ã€å·¥å…·æ‰§è¡Œã€ç»“æœå¤„ç†ç­‰ï¼‰
# ä¸€è½®å®Œæ•´çš„"å·¥å…·è°ƒç”¨"é€šå¸¸éœ€è¦ 2-3 ä¸ªæ­¥æ•°ï¼šLLMç”Ÿæˆå·¥å…·è°ƒç”¨ â†’ æ‰§è¡Œå·¥å…· â†’ LLMå¤„ç†ç»“æœ
# å»ºè®®å€¼ï¼š50 (çº¦å¯æ”¯æŒ 15-20 è½®å·¥å…·è°ƒç”¨)ï¼Œ25 (çº¦å¯æ”¯æŒ 8-10 è½®å·¥å…·è°ƒç”¨)
# è¾¾åˆ°æ­¤é™åˆ¶åä¼šæç¤ºç”¨æˆ·æ˜¯å¦ç»§ç»­
# ã€å·²åºŸå¼ƒã€‘æ­¤å¸¸é‡å·²ç§»è‡³ç”¨æˆ·é…ç½®ä¸­ï¼Œä¿ç•™ä»…ä½œä¸ºåå¤‡é»˜è®¤å€¼
RECURSION_LIMIT = 25  # åå¤‡é»˜è®¤å€¼

import json
import asyncio
import logging
from typing import Optional
from channels.generic.websocket import AsyncWebsocketConsumer
from channels.db import database_sync_to_async
from asgiref.sync import sync_to_async
from langchain_core.messages import HumanMessage, AIMessage, AIMessageChunk, ToolMessage
from django.contrib.auth.models import User

from logger import logger

# ========== å¼‚æ­¥ App è·å– ==========
# ç¼“å­˜ç¼–è¯‘åçš„ app å®ä¾‹
_cached_async_app = None

async def get_async_app():
    """
    è·å–å¸¦æœ‰å¼‚æ­¥ checkpointer çš„ appï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    å¿…é¡»åœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­è°ƒç”¨
    """
    global _cached_async_app
    if _cached_async_app is None:
        from agent_service.agent_graph import get_app_with_checkpointer
        _cached_async_app = await get_app_with_checkpointer()
        logger.info("[Consumers] å¼‚æ­¥ App å·²åˆå§‹åŒ–")
    return _cached_async_app

class AgentConsumer(AsyncWebsocketConsumer):
    """
    Agent WebSocket Consumer
    
    URL: ws://host/ws/agent/?active_experts=planner,chat&session_id=xxx
    
    æ¶ˆæ¯åè®®:
    - å®¢æˆ·ç«¯ -> æœåŠ¡å™¨:
        {"type": "message", "content": "ç”¨æˆ·æ¶ˆæ¯"}
        {"type": "ping"}
    
    - æœåŠ¡å™¨ -> å®¢æˆ·ç«¯:
        {"type": "token", "content": "æµå¼token"}
        {"type": "message", "content": "å®Œæ•´æ¶ˆæ¯", "finished": true}
        {"type": "tool_call", "name": "tool_name", "args": {...}}
        {"type": "tool_result", "name": "tool_name", "result": "..."}
        {"type": "error", "message": "é”™è¯¯ä¿¡æ¯"}
        {"type": "pong"}
    """
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.user: Optional[User] = None
        self.session_id: Optional[str] = None
        self.active_tools: list = []  # å¯ç”¨çš„å·¥å…·åˆ—è¡¨
        self.graph = None
        self.is_processing = False
        self.should_stop = False  # åœæ­¢æ ‡å¿—
        self.current_task: Optional[asyncio.Task] = None  # å½“å‰å¤„ç†ä»»åŠ¡
    
    async def connect(self):
        """å¤„ç† WebSocket è¿æ¥"""
        # 1. éªŒè¯ç”¨æˆ·èº«ä»½
        self.user = self.scope.get("user")
        if not self.user or not self.user.is_authenticated:
            logger.warning("æœªè®¤è¯ç”¨æˆ·å°è¯•è¿æ¥ WebSocket")
            await self.close(code=4001)
            return
        
        # 2. è§£æ URL å‚æ•°
        query_string = self.scope.get("query_string", b"").decode()
        params = self._parse_query_string(query_string)
        
        self.session_id = params.get("session_id", f"user_{self.user.id}_default")
        
        # è·å–å¯ç”¨çš„å·¥å…·
        # æ³¨æ„ï¼šåŒºåˆ†"æœªä¼ é€’å‚æ•°"å’Œ"ä¼ é€’ç©ºå‚æ•°"ï¼š
        # - æœªä¼ é€’å‚æ•°ï¼ˆNoneï¼‰ï¼šä½¿ç”¨é»˜è®¤å·¥å…·
        # - ä¼ é€’ç©ºå‚æ•°ï¼ˆ""ï¼‰ï¼šä¸å¯ç”¨ä»»ä½•å·¥å…·ï¼ˆç”¨æˆ·æ˜ç¡®é€‰æ‹©ä¸ºç©ºï¼‰
        from agent_service.agent_graph import get_default_tools
        tools_param = params.get("active_tools")  # None æˆ– å­—ç¬¦ä¸²
        if tools_param is None:
            # æœªä¼ é€’å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·
            self.active_tools = get_default_tools()
            logger.debug(f"æœªæŒ‡å®šå·¥å…·å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·: {len(self.active_tools)} ä¸ª")
        elif tools_param == "":
            # ä¼ é€’äº†ç©ºå‚æ•°ï¼Œç”¨æˆ·æ˜ç¡®é€‰æ‹©ä¸å¯ç”¨ä»»ä½•å·¥å…·
            self.active_tools = []
            logger.debug(f"ç”¨æˆ·æ˜ç¡®é€‰æ‹©ä¸å¯ç”¨ä»»ä½•å·¥å…·")
        else:
            # ä¼ é€’äº†å…·ä½“çš„å·¥å…·åˆ—è¡¨
            self.active_tools = [t.strip() for t in tools_param.split(",") if t.strip()]
            logger.debug(f"ç”¨æˆ·é€‰æ‹©å·¥å…·: {self.active_tools}")
        
        logger.info(f"ç”¨æˆ· {self.user.username} è¿æ¥ WebSocket, session={self.session_id}, tools={len(self.active_tools)} ä¸ª")
        
        # 3. åˆå§‹åŒ– Agent Graph
        await self._init_graph()
        
        # 4. æ¥å—è¿æ¥
        await self.accept()
        
        # 5. åŠ å…¥ session groupï¼ˆç”¨äºå¹¿æ’­æ¶ˆæ¯ï¼‰
        self.group_name = f"agent_session_{self.session_id}"
        await self.channel_layer.group_add(self.group_name, self.channel_name)
        logger.info(f"âœ… å·²åŠ å…¥ channel group: {self.group_name}")
        
        # 6. è·å–å½“å‰æ¶ˆæ¯æ•°é‡
        current_message_count = 0
        try:
            app = await get_async_app()
            config = {"configurable": {"thread_id": self.session_id}}
            state = await app.aget_state(config)
            if state and state.values:
                messages = state.values.get("messages", [])
                current_message_count = len(messages)
        except Exception as e:
            logger.warning(f"[WebSocket] è·å–æ¶ˆæ¯æ•°é‡å¤±è´¥: {e}")
        
        # 6. æ£€æŸ¥ä¼šè¯å‘½åçŠ¶æ€
        is_naming = False
        session_name = ""
        try:
            from agent_service.models import AgentSession
            session = await database_sync_to_async(
                AgentSession.objects.filter(session_id=self.session_id).first
            )()
            if session:
                is_naming = session.is_naming
                session_name = session.name
        except Exception as e:
            logger.warning(f"[WebSocket] æ£€æŸ¥å‘½åçŠ¶æ€å¤±è´¥: {e}")
        
        # 7. å‘é€æ¬¢è¿æ¶ˆæ¯ï¼ˆåŒ…å«æ¶ˆæ¯æ•°é‡å’Œå‘½åçŠ¶æ€ï¼‰
        await self.send_json({
            "type": "connected",
            "session_id": self.session_id,
            "active_tools": self.active_tools,
            "message_count": current_message_count,
            "is_naming": is_naming,
            "session_name": session_name,
            "message": f"æ¬¢è¿, {self.user.username}!"
        })
    
    async def send_json(self, content, close=False):
        """é‡å†™ send_jsonï¼Œä½¿ç”¨ channel_layer å¹¿æ’­æ¶ˆæ¯åˆ°æ‰€æœ‰è¿æ¥"""
        # å¦‚æœæ˜¯æµå¼ç›¸å…³æ¶ˆæ¯ï¼Œé€šè¿‡ channel_layer å¹¿æ’­
        msg_type = content.get("type")
        if msg_type in ["stream_start", "stream_chunk", "tool_call", "tool_result", "stream_end", "finished"]:
            # é€šè¿‡ channel_layer å¹¿æ’­åˆ° group ä¸­æ‰€æœ‰è¿æ¥
            if hasattr(self, 'group_name') and self.channel_layer:
                await self.channel_layer.group_send(
                    self.group_name,
                    {
                        "type": "broadcast_message",
                        "content": content
                    }
                )
            else:
                # æ²¡æœ‰ channel_layerï¼Œå›é€€åˆ°ç›´æ¥å‘é€
                await self.send(text_data=json.dumps(content, ensure_ascii=False))
        else:
            # éæµå¼æ¶ˆæ¯ï¼Œç›´æ¥å‘é€
            await self.send(text_data=json.dumps(content, ensure_ascii=False))
    
    async def broadcast_message(self, event):
        """æ¥æ”¶ channel_layer å¹¿æ’­çš„æ¶ˆæ¯å¹¶å‘é€ç»™å®¢æˆ·ç«¯"""
        content = event["content"]
        await self.send(text_data=json.dumps(content, ensure_ascii=False))
    
    async def disconnect(self, close_code):
        """å¤„ç† WebSocket æ–­å¼€"""
        logger.info(f"ç”¨æˆ· {self.user.username if self.user else 'unknown'} æ–­å¼€ WebSocket, code={close_code}")
        
        # ç¦»å¼€ channel group
        if hasattr(self, 'group_name'):
            await self.channel_layer.group_discard(self.group_name, self.channel_name)
            logger.info(f"ğŸšª å·²ç¦»å¼€ channel group: {self.group_name}")
    
    async def receive(self, text_data):
        """å¤„ç†æ”¶åˆ°çš„æ¶ˆæ¯"""
        try:
            data = json.loads(text_data)
            msg_type = data.get("type", "message")
            
            if msg_type == "ping":
                # å¿ƒè·³å“åº”
                await self.send_json({"type": "pong"})
                
            elif msg_type == "stop":
                # åœæ­¢å½“å‰å¤„ç†
                if self.is_processing:
                    self.should_stop = True
                    # å–æ¶ˆå½“å‰ä»»åŠ¡
                    if self.current_task and not self.current_task.done():
                        self.current_task.cancel()
                        logger.info(f"ç”¨æˆ· {self.user.username} å–æ¶ˆäº†å½“å‰ä»»åŠ¡")
                    logger.info(f"ç”¨æˆ· {self.user.username} è¯·æ±‚åœæ­¢å¤„ç†")
                    # ã€ä¿®å¤ã€‘ä¸è¦åœ¨è¿™é‡Œå‘é€ stoppedï¼Œè®©ä»»åŠ¡å–æ¶ˆååœ¨ finally ä¸­ç»Ÿä¸€å¤„ç†
                    # await self.send_json({"type": "stopped", "message": "å·²åœæ­¢ç”Ÿæˆ"})
                else:
                    await self.send_json({"type": "info", "message": "å½“å‰æ²¡æœ‰æ­£åœ¨å¤„ç†çš„æ¶ˆæ¯"})
                
            elif msg_type == "message":
                # ç”¨æˆ·æ¶ˆæ¯
                content = data.get("content", "").strip()
                attachment_ids = data.get("attachment_ids", [])
                if not content:
                    await self.send_json({"type": "error", "message": "æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º"})
                    return
                
                if self.is_processing:
                    await self.send_json({"type": "error", "message": "æ­£åœ¨å¤„ç†ä¸Šä¸€æ¡æ¶ˆæ¯ï¼Œè¯·ç¨å€™"})
                    return
                
                # é‡ç½®åœæ­¢æ ‡å¿—
                self.should_stop = False
                # åˆ›å»ºä»»åŠ¡å¹¶è¿è¡Œ
                self.current_task = asyncio.create_task(self._process_message(content, attachment_ids=attachment_ids))
            
            elif msg_type == "continue":
                # ç”¨æˆ·é€‰æ‹©ç»§ç»­æ‰§è¡Œï¼ˆè¾¾åˆ°é€’å½’é™åˆ¶åï¼‰
                logger.info(f"ç”¨æˆ· {self.user.username} é€‰æ‹©ç»§ç»­æ‰§è¡Œ")
                if self.is_processing:
                    await self.send_json({"type": "error", "message": "æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™"})
                    return
                
                # é‡ç½®åœæ­¢æ ‡å¿—å¹¶ç»§ç»­
                self.should_stop = False
                self.current_task = asyncio.create_task(self._continue_processing())
            
            elif msg_type == "check_status":
                # æŸ¥è¯¢å½“å‰ä¼šè¯çš„å¤„ç†çŠ¶æ€ï¼ˆç”¨äºåˆ·æ–°åæ¢å¤æµå¼çŠ¶æ€ï¼‰
                logger.info(f"ç”¨æˆ· {self.user.username} æŸ¥è¯¢ä¼šè¯çŠ¶æ€")
                
                # è·å– LangGraph çš„å®é™…çŠ¶æ€
                has_pending_messages = False
                last_message_role = None
                should_sync_immediately = False
                try:
                    app = await get_async_app()
                    config = {"configurable": {"thread_id": self.session_id}}
                    state = await app.aget_state(config)
                    if state and state.values:
                        messages = state.values.get("messages", [])
                        if messages:
                            last_msg = messages[-1]
                            last_message_role = getattr(last_msg, 'type', None)
                            # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å·¥å…·æ¶ˆæ¯æˆ–äººç±»æ¶ˆæ¯ï¼Œè¯´æ˜è¿˜éœ€è¦ç»§ç»­å¤„ç†
                            if last_message_role in ['tool', 'human']:
                                has_pending_messages = True
                            # å¦‚æœæœ€åä¸€æ¡æ˜¯ AI æ¶ˆæ¯ä¸”ä¸åœ¨å¤„ç†ä¸­ï¼Œè¯´æ˜æµå¼è¾“å‡ºå·²å®Œæˆï¼Œå‰ç«¯åº”è¯¥ç«‹å³åŒæ­¥
                            elif last_message_role == 'ai' and not self.is_processing:
                                should_sync_immediately = True
                                logger.info(f"æ£€æµ‹åˆ°æµå¼è¾“å‡ºå·²å®Œæˆï¼Œå»ºè®®å‰ç«¯ç«‹å³åŒæ­¥")
                except Exception as e:
                    logger.warning(f"è·å– LangGraph çŠ¶æ€å¤±è´¥: {e}")
                
                await self.send_json({
                    "type": "status_response",
                    "session_id": self.session_id,
                    "is_processing": self.is_processing,
                    "should_stop": self.should_stop,
                    "has_pending_messages": has_pending_messages,
                    "last_message_role": last_message_role,
                    "should_sync_immediately": should_sync_immediately
                })
                
            else:
                await self.send_json({"type": "error", "message": f"æœªçŸ¥æ¶ˆæ¯ç±»å‹: {msg_type}"})
                
        except json.JSONDecodeError:
            await self.send_json({"type": "error", "message": "æ— æ•ˆçš„ JSON æ ¼å¼"})
        except Exception as e:
            logger.exception(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            await self.send_json({"type": "error", "message": f"æœåŠ¡å™¨é”™è¯¯: {str(e)}"})
    
    async def _build_human_message(self, content: str, attachment_ids: list = None) -> HumanMessage:
        """
        æ„å»º HumanMessageï¼Œæ”¯æŒå¤šæ¨¡æ€é™„ä»¶ã€‚
        
        æ ¸å¿ƒæ”¹é€ ï¼š
        1. content åªåŒ…å«ç”¨æˆ·è¾“å…¥æ–‡æœ¬ï¼ˆå›¾ç‰‡é™¤å¤–ï¼Œå›¾ç‰‡ä»¥ image_url å—å½¢å¼åŒ…å«ï¼‰
        2. é™„ä»¶çš„æè¿°ä¿¡æ¯ï¼ˆç»™ LLM çœ‹ï¼‰å­˜åˆ° additional_kwargs['attachments_context']
        3. é™„ä»¶å…ƒæ•°æ®ï¼ˆç»™å‰ç«¯å†å²æ¸²æŸ“ï¼‰å­˜åˆ° additional_kwargs['attachments_metadata']
        """
        if not attachment_ids:
            return HumanMessage(content=content)
        
        try:
            from agent_service.attachment_handler import AttachmentHandler
            from agent_service.models import SessionAttachment
            
            # å¼‚æ­¥æŸ¥è¯¢é™„ä»¶
            attachments = await database_sync_to_async(
                lambda: list(SessionAttachment.objects.filter(
                    id__in=attachment_ids, user=self.user, is_deleted=False
                ))
            )()
            
            if not attachments:
                return HumanMessage(content=content)
            
            # æ„å»ºé™„ä»¶å…ƒæ•°æ®ï¼ˆä¾›å‰ç«¯å†å²æ¸²æŸ“ï¼‰
            attachments_metadata = []
            for att in attachments:
                meta = {
                    'sa_id': att.id,
                    'type': att.type,
                    'filename': att.filename,
                    'mime_type': att.mime_type,
                }
                if att.is_internal:
                    meta['internal_type'] = att.internal_type
                    meta['internal_id'] = att.internal_id
                    meta['name'] = att.filename  # å…ƒç´ æ ‡é¢˜/åç§°
                if att.file:
                    meta['file_url'] = att.file.url
                if att.thumbnail:
                    meta['thumbnail_url'] = att.thumbnail.url
                attachments_metadata.append(meta)
            
            # æ„å»ºå¤šæ¨¡æ€ content_blocksï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦æœ‰å›¾ç‰‡ï¼Œä»¥åŠç»™ LLM çš„ä¸Šä¸‹æ–‡ï¼‰
            content_blocks = await database_sync_to_async(
                AttachmentHandler.format_for_message
            )(attachments, user=self.user)
            
            if not content_blocks:
                return HumanMessage(
                    content=content,
                    additional_kwargs={
                        'attachment_ids': attachment_ids,
                        'attachments_metadata': attachments_metadata,
                    }
                )
            
            # åˆ†ç¦»å›¾ç‰‡å—å’Œæ–‡æœ¬å—
            image_blocks = [b for b in content_blocks if b.get('type') == 'image_url']
            text_blocks = [b for b in content_blocks if b.get('type') == 'text']
            
            # æ ‡è®°é™„ä»¶ä¸ºå·²å‘é€
            att_ids = [a.id for a in attachments]
            await database_sync_to_async(
                AttachmentHandler.mark_sent
            )(att_ids, message_index=0)
            
            if image_blocks:
                # æœ‰å›¾ç‰‡ï¼šæ„å»ºå¤šæ¨¡æ€ contentï¼ˆtext + imagesï¼‰ï¼Œæ–‡æœ¬å—ä½œä¸ºé™„ä»¶ä¸Šä¸‹æ–‡
                multimodal_content = [{"type": "text", "text": content}]
                multimodal_content.extend(image_blocks)
                
                # æå–çº¯æ–‡æœ¬é™„ä»¶çš„æè¿°ï¼ˆç»™ LLM çš„ä¸Šä¸‹æ–‡ï¼‰
                attachments_context = '\n\n'.join(b.get('text', '') for b in text_blocks)
                
                # ä¼°ç®—å›¾ç‰‡ token æ•°ï¼ˆOpenAI è§†è§‰æ¨¡å‹çš„ç²—ç•¥ä¼°ç®—ï¼‰
                # å‚è€ƒ: ä½ç»†èŠ‚å›¾ç‰‡çº¦ 85 tokens, é«˜ç»†èŠ‚å›¾ç‰‡çº¦ 170-765 tokens (å–å†³äºåˆ†å—æ•°)
                # è¿™é‡Œå‡è®¾ä½¿ç”¨ detail="auto" é…ç½®ï¼Œå¹³å‡çº¦ 85-100 tokens/å›¾
                estimated_tokens_per_image = 85
                estimated_image_tokens = len(image_blocks) * estimated_tokens_per_image
                
                logger.debug(
                    f"[å¤šæ¨¡æ€] æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯: {len(image_blocks)} å¼ å›¾ç‰‡, "
                    f"é™„ä»¶ä¸Šä¸‹æ–‡ {len(attachments_context)} å­—ç¬¦, "
                    f"é¢„ä¼°å›¾ç‰‡Tokenâ‰ˆ{estimated_image_tokens} (æŒ‰{estimated_tokens_per_image}token/å›¾)"
                )
                
                return HumanMessage(
                    content=multimodal_content,
                    additional_kwargs={
                        'attachment_ids': attachment_ids,
                        'attachments_metadata': attachments_metadata,
                        'attachments_context': attachments_context,
                    }
                )
            else:
                # çº¯æ–‡æœ¬é™„ä»¶ï¼šcontent åªåŒ…å«ç”¨æˆ·è¾“å…¥ï¼Œé™„ä»¶æè¿°å­˜åˆ° attachments_context
                attachments_context = '\n\n'.join(b.get('text', '') for b in text_blocks)
                
                logger.debug(f"[é™„ä»¶] çº¯æ–‡æœ¬é™„ä»¶: {len(attachments)} ä¸ª, ä¸Šä¸‹æ–‡ {len(attachments_context)} å­—ç¬¦")
                
                return HumanMessage(
                    content=content,
                    additional_kwargs={
                        'attachment_ids': attachment_ids,
                        'attachments_metadata': attachments_metadata,
                        'attachments_context': attachments_context,
                    }
                )
            
        except Exception as e:
            logger.error(f"[å¤šæ¨¡æ€] æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
            # é™çº§ä¸ºçº¯æ–‡æœ¬
            return HumanMessage(content=content)

    async def _process_message(self, content: str, attachment_ids: list = None):
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶çœŸæ­£æµå¼è¾“å‡º
        ä½¿ç”¨ stream_mode="messages" è·å– token çº§åˆ«çš„æµå¼è¾“å‡º
        
        Args:
            content: ç”¨æˆ·æ¶ˆæ¯æ–‡æœ¬
            attachment_ids: SessionAttachment IDsï¼ˆç”¨äºæ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯ï¼‰
        """
        self.is_processing = True
        
        try:
            # é€šçŸ¥å¼€å§‹å¤„ç†
            await self.send_json({"type": "processing", "message": "æ­£åœ¨æ€è€ƒ..."})
            
            # å‡†å¤‡é…ç½®
            # ä»ç”¨æˆ·é…ç½®è¯»å– recursion_limit
            from agent_service.context_optimizer import get_optimization_config
            opt_config = await database_sync_to_async(get_optimization_config)(self.user)
            recursion_limit = opt_config.get('recursion_limit', RECURSION_LIMIT)
            
            config = {
                "configurable": {
                    "thread_id": self.session_id,
                    "user": self.user,
                    "active_tools": self.active_tools  # ä¼ é€’ active_tools åˆ° config
                },
                "recursion_limit": recursion_limit  # ä»ç”¨æˆ·é…ç½®è¯»å–ï¼Œå•æ¬¡å¯¹è¯æœ€å¤§å·¥å…·è°ƒç”¨æ­¥æ•°
            }
            
            # è·å–å¼‚æ­¥ app
            app = await get_async_app()
            
            # ========== ã€å…³é”®ã€‘é…é¢æ£€æŸ¥ ==========
            from agent_service.context_optimizer import check_quota_available, get_current_model_config
            
            current_model_id, _ = await database_sync_to_async(get_current_model_config)(self.user)
            quota_info = await database_sync_to_async(check_quota_available)(self.user, current_model_id)
            
            if not quota_info.get('available', True):
                # é…é¢ä¸è¶³ï¼Œæ‹’ç»å¤„ç†
                await self.send_json({
                    "type": "quota_exceeded",
                    "message": quota_info.get('message', "æ‚¨æœ¬æœˆçš„æŠµç”¨é‡‘å·²ç”¨å°½ï¼Œè¯·ä½¿ç”¨è‡ªå·±çš„æ¨¡å‹æˆ–ç­‰å¾…ä¸‹ä¸ªæœˆ"),
                    "monthly_credit": quota_info.get('monthly_credit', 0),
                    "monthly_used": quota_info.get('monthly_used', 0),
                    "remaining": quota_info.get('remaining', 0)
                })
                self.is_processing = False
                return
            
            # ========== ã€å…³é”®ã€‘æ£€æŸ¥æ˜¯å¦æ˜¯ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼Œå†³å®šæ˜¯å¦è‡ªåŠ¨å‘½å ==========
            is_first_message = False
            try:
                current_state = await app.aget_state(config)
                if not current_state or not current_state.values or not current_state.values.get("messages"):
                    is_first_message = True
                    logger.info(f"[è‡ªåŠ¨å‘½å] æ£€æµ‹åˆ°ç¬¬ä¸€æ¡æ¶ˆæ¯: {content[:50]}...")
            except Exception as e:
                logger.warning(f"[è‡ªåŠ¨å‘½å] æ£€æŸ¥ç¬¬ä¸€æ¡æ¶ˆæ¯å¤±è´¥: {e}")
            
            # å¦‚æœæ˜¯ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼Œæ‰§è¡Œè‡ªåŠ¨å‘½åï¼ˆåœ¨å›å¤ä¹‹å‰ï¼‰
            if is_first_message:
                await self._auto_name_session(content)
            
            # ========== ã€å…³é”®ã€‘å‘é€å‰æ£€æŸ¥å¹¶æ‰§è¡Œå†å²æ€»ç»“ ==========
            # è·å–å½“å‰å†å²æ¶ˆæ¯ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ€»ç»“
            try:
                current_state = await app.aget_state(config)
                if current_state and current_state.values:
                    current_messages = current_state.values.get("messages", [])
                    if current_messages:
                        await self._check_and_summarize(current_messages, config)
            except Exception as e:
                logger.warning(f"[æ€»ç»“] å‘é€å‰æ£€æŸ¥å¤±è´¥: {e}")
            
            # ========== æ›´æ–° last_message_preview ==========
            await self._update_last_message_preview(content)
            
            # å‡†å¤‡è¾“å…¥ â€” æ”¯æŒå¤šæ¨¡æ€ï¼ˆattachment_ids â†’ content_blocksï¼‰
            human_message = await self._build_human_message(content, attachment_ids)
            
            input_state = {
                "messages": [human_message],
                "active_tools": self.active_tools
            }
            
            # æµå¼è¾“å‡ºçŠ¶æ€
            stream_started = False
            
            # ã€é‡æ„ã€‘ä½¿ç”¨å¼‚æ­¥ astream æ›¿ä»£åŒæ­¥ stream + åå°çº¿ç¨‹
            # è¿™æ · asyncio.CancelledError å¯ä»¥ä¼ æ’­åˆ°åº•å±‚ HTTP å®¢æˆ·ç«¯å¹¶ä¸­æ–­è¯·æ±‚
            try:
                logger.debug(f"[Stream] å¼€å§‹å¼‚æ­¥æµå¼å¤„ç†")
                chunk_count = 0
                
                async for output in app.astream(input_state, config):
                    # æ£€æŸ¥åœæ­¢æ ‡å¿—
                    if self.should_stop:
                        logger.debug(f"[Stream] æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œä¸­æ–­å¤„ç†")
                        break
                    
                    chunk_count += 1
                    
                    # output æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œkey æ˜¯èŠ‚ç‚¹åç§°ï¼Œvalue æ˜¯è¯¥èŠ‚ç‚¹çš„è¾“å‡º
                    for node_name, node_output in output.items():
                        if self.should_stop:
                            logger.debug(f"[Stream] æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œä¸­æ–­èŠ‚ç‚¹å¤„ç†")
                            break
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰ messages
                        if isinstance(node_output, dict) and 'messages' in node_output:
                            for msg in node_output['messages']:
                                if self.should_stop:
                                    logger.debug(f"[Stream] æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œä¸­æ–­æ¶ˆæ¯å¤„ç†")
                                    break
                                
                                # å¤„ç† AIMessage çš„å†…å®¹
                                if hasattr(msg, 'content') and msg.content:
                                    if not stream_started:
                                        await self.send_json({"type": "stream_start"})
                                        stream_started = True
                                    await self.send_json({
                                        "type": "stream_chunk",
                                        "content": msg.content
                                    })
                                
                                # å¤„ç†å·¥å…·è°ƒç”¨
                                if hasattr(msg, 'tool_calls') and msg.tool_calls:
                                    if stream_started:
                                        await self.send_json({"type": "stream_end"})
                                        stream_started = False
                                    for tc in msg.tool_calls:
                                        await self.send_json({
                                            "type": "tool_call",
                                            "name": tc.get("name", "unknown"),
                                            "args": tc.get("args", {})
                                        })
                                
                                # å¤„ç† ToolMessage
                                if hasattr(msg, 'type') and getattr(msg, 'type', None) == 'tool':
                                    result_str = str(msg.content) if hasattr(msg, 'content') else str(msg)
                                    tool_name = msg.name if hasattr(msg, 'name') else "tool"
                                    # æ ¹æ®å·¥å…·åç§°ç¡®å®šéœ€è¦åˆ·æ–°çš„æ•°æ®ç±»å‹
                                    refresh_types = self._get_refresh_types_for_tool(tool_name)
                                    await self.send_json({
                                        "type": "tool_result",
                                        "name": tool_name,
                                        "result": result_str,
                                        "refresh": refresh_types
                                    })
                    
                    # æ¯æ¬¡è¿­ä»£åè®©å‡ºæ§åˆ¶æƒï¼Œå…è®¸å¤„ç†å–æ¶ˆä¿¡å·
                    await asyncio.sleep(0)
                
                logger.debug(f"[Stream] å¼‚æ­¥æµå¼å¤„ç†å®Œæˆ, å…± {chunk_count} ä¸ª outputs")
                
            except asyncio.CancelledError:
                logger.debug(f"[Stream] å¼‚æ­¥æµå¼å¤„ç†è¢«å–æ¶ˆ")
                raise  # é‡æ–°æŠ›å‡ºè®©å¤–å±‚å¤„ç†
            except Exception as e:
                error_str = str(e)
                logger.exception(f"[Stream] å¼‚æ­¥æµå¼å¤„ç†å¼‚å¸¸: {e}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯é€’å½’é™åˆ¶é”™è¯¯
                if "Recursion limit" in error_str or "GraphRecursionError" in type(e).__name__:
                    logger.warning(f"è¾¾åˆ°é€’å½’é™åˆ¶: {error_str}")
                    if stream_started:
                        await self.send_json({"type": "stream_end"})
                        stream_started = False
                    
                    await self.send_json({
                        "type": "recursion_limit",
                        "message": "å·¥å…·è°ƒç”¨æ¬¡æ•°è¾¾åˆ°ä¸Šé™ï¼Œæ˜¯å¦ç»§ç»­æ‰§è¡Œï¼Ÿ"
                    })
                    return  # é€’å½’é™åˆ¶ä¸ç®—é”™è¯¯ï¼Œç›´æ¥è¿”å›
                else:
                    raise  # å…¶ä»–å¼‚å¸¸é‡æ–°æŠ›å‡º
            
            # ç¡®ä¿æµæ­£ç¡®ç»“æŸ
            if stream_started:
                await self.send_json({"type": "stream_end"})
            
            # è·å–æœ€ç»ˆæ¶ˆæ¯æ•°é‡
            final_message_count = 0
            final_messages = []
            try:
                final_state = await app.aget_state(config)
                if final_state and final_state.values:
                    final_messages = final_state.values.get("messages", [])
                    final_message_count = len(final_messages)
            except Exception as e:
                logger.warning(f"è·å–æœ€ç»ˆæ¶ˆæ¯æ•°é‡å¤±è´¥: {e}")
            
            # å‘é€å®Œæˆä¿¡å·ï¼ˆåŒ…å«æ¶ˆæ¯æ•°é‡ï¼‰
            if not self.should_stop:
                await self.send_json({
                    "type": "finished",
                    "message": "å¤„ç†å®Œæˆ",
                    "message_count": final_message_count
                })
                
                # æ³¨æ„ï¼šæ€»ç»“æ£€æŸ¥å·²ç§»è‡³å‘é€å‰æ‰§è¡Œï¼Œå›å¤åä¸å†æ£€æŸ¥
            
        except asyncio.CancelledError:
            logger.info(f"æ¶ˆæ¯å¤„ç†ä»»åŠ¡è¢«å–æ¶ˆ")
            # ã€é‡è¦ã€‘ä»»åŠ¡å–æ¶ˆæ—¶ï¼Œç¡®ä¿æµå¼çŠ¶æ€æ­£ç¡®ç»“æŸ
            try:
                await self.send_json({"type": "stream_end"})
            except:
                pass
            
            # ã€é‡è¦ã€‘æ¸…ç†å¯èƒ½ä¸å®Œæ•´çš„çŠ¶æ€ï¼Œç¡®ä¿ä¸‹æ¬¡å¯¹è¯èƒ½æ­£å¸¸è¿›è¡Œ
            try:
                await self._cleanup_after_stop(config)
            except Exception as cleanup_error:
                logger.warning(f"åœæ­¢åæ¸…ç†çŠ¶æ€å¤±è´¥: {cleanup_error}")
            
            # å‘é€ stopped æ¶ˆæ¯
            await self.send_json({"type": "stopped", "message": "å·²åœæ­¢ç”Ÿæˆ"})
        except Exception as e:
            logger.exception(f"Agent è°ƒç”¨å¤±è´¥: {e}")
            await self.send_json({
                "type": "error",
                "message": f"Agent è°ƒç”¨å¤±è´¥: {str(e)}"
            })
        finally:
            self.is_processing = False
            self.current_task = None
            self.should_stop = False

    async def _continue_processing(self):
        """
        ç»§ç»­å¤„ç†ï¼ˆè¾¾åˆ°é€’å½’é™åˆ¶åç”¨æˆ·é€‰æ‹©ç»§ç»­ï¼‰
        æ·»åŠ ä¸€æ¡ç»§ç»­æ‰§è¡Œçš„æ¶ˆæ¯ï¼Œè®© Agent ä»ä¸­æ–­å¤„ç»§ç»­
        ã€é‡æ„ã€‘ä½¿ç”¨å¼‚æ­¥ astream æ›¿ä»£åŒæ­¥ stream + åå°çº¿ç¨‹
        """
        self.is_processing = True
        
        try:
            await self.send_json({"type": "processing", "message": "ç»§ç»­æ‰§è¡Œ..."})
            
            app = await get_async_app()
            from langchain_core.messages import HumanMessage
            
            config = {
                "configurable": {
                    "thread_id": self.session_id,
                    "user": self.user,
                    "active_tools": self.active_tools
                },
                "recursion_limit": RECURSION_LIMIT  # å•æ¬¡å¯¹è¯æœ€å¤§å·¥å…·è°ƒç”¨æ­¥æ•°
            }
            
            # å…ˆæ£€æŸ¥å¹¶æ¸…ç†ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨
            await self._cleanup_incomplete_tool_calls(config)
            
            # æ„å»ºç»§ç»­æ‰§è¡Œçš„è¾“å…¥æ¶ˆæ¯
            continue_message = HumanMessage(content="ç»§ç»­æ‰§è¡Œä¸Šè¿°ä»»åŠ¡ï¼Œå®Œæˆæœªå®Œæˆçš„å·¥ä½œã€‚")
            input_state = {"messages": [continue_message]}
            
            stream_started = False
            
            # ã€é‡æ„ã€‘ä½¿ç”¨å¼‚æ­¥ astream
            try:
                logger.info(f"[Continue] å¼€å§‹å¼‚æ­¥ç»§ç»­æ‰§è¡Œ")
                chunk_count = 0
                
                async for output in app.astream(input_state, config):
                    if self.should_stop:
                        logger.info(f"[Continue] æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œä¸­æ–­å¤„ç†")
                        break
                    
                    chunk_count += 1
                    
                    for node_name, node_output in output.items():
                        if self.should_stop:
                            break
                        
                        if isinstance(node_output, dict) and 'messages' in node_output:
                            for msg in node_output['messages']:
                                if self.should_stop:
                                    break
                                
                                # å¤„ç† AIMessage å†…å®¹
                                if hasattr(msg, 'content') and msg.content:
                                    has_tool_calls = hasattr(msg, 'tool_calls') and msg.tool_calls
                                    if not has_tool_calls:
                                        if not stream_started:
                                            await self.send_json({"type": "stream_start"})
                                            stream_started = True
                                        await self.send_json({
                                            "type": "stream_chunk",
                                            "content": msg.content
                                        })
                                
                                # å¤„ç†å·¥å…·è°ƒç”¨
                                if hasattr(msg, 'tool_calls') and msg.tool_calls:
                                    if stream_started:
                                        await self.send_json({"type": "stream_end"})
                                        stream_started = False
                                    for tc in msg.tool_calls:
                                        await self.send_json({
                                            "type": "tool_call",
                                            "name": tc.get("name", "unknown"),
                                            "args": tc.get("args", {})
                                        })
                                
                                # å¤„ç† ToolMessage
                                if hasattr(msg, 'type') and getattr(msg, 'type', None) == 'tool':
                                    result_str = str(msg.content) if hasattr(msg, 'content') else str(msg)
                                    tool_name = msg.name if hasattr(msg, 'name') else "tool"
                                    # æ ¹æ®å·¥å…·åç§°ç¡®å®šéœ€è¦åˆ·æ–°çš„æ•°æ®ç±»å‹
                                    refresh_types = self._get_refresh_types_for_tool(tool_name)
                                    await self.send_json({
                                        "type": "tool_result",
                                        "name": tool_name,
                                        "result": result_str,
                                        "refresh": refresh_types
                                    })
                    
                    # è®©å‡ºæ§åˆ¶æƒ
                    await asyncio.sleep(0)
                
                logger.info(f"[Continue] å¼‚æ­¥ç»§ç»­æ‰§è¡Œå®Œæˆ, å…± {chunk_count} ä¸ª outputs")
                
            except asyncio.CancelledError:
                logger.info(f"[Continue] å¼‚æ­¥ç»§ç»­æ‰§è¡Œè¢«å–æ¶ˆ")
                raise
            except Exception as e:
                error_str = str(e)
                logger.exception(f"[Continue] å¼‚æ­¥ç»§ç»­æ‰§è¡Œå¼‚å¸¸: {e}")
                
                if "Recursion limit" in error_str or "GraphRecursionError" in type(e).__name__:
                    logger.warning(f"ç»§ç»­æ‰§è¡Œæ—¶å†æ¬¡è¾¾åˆ°é€’å½’é™åˆ¶: {error_str}")
                    if stream_started:
                        await self.send_json({"type": "stream_end"})
                        stream_started = False
                    
                    await self.send_json({
                        "type": "recursion_limit",
                        "message": "å·¥å…·è°ƒç”¨æ¬¡æ•°å†æ¬¡è¾¾åˆ°ä¸Šé™ï¼Œæ˜¯å¦ç»§ç»­æ‰§è¡Œï¼Ÿ"
                    })
                    return
                else:
                    raise
            
            # ç¡®ä¿æµæ­£ç¡®ç»“æŸ
            if stream_started:
                await self.send_json({"type": "stream_end"})
            
            # è·å–æœ€ç»ˆæ¶ˆæ¯æ•°é‡
            final_message_count = 0
            try:
                final_state = await app.aget_state(config)
                if final_state and final_state.values:
                    final_messages = final_state.values.get("messages", [])
                    final_message_count = len(final_messages)
            except Exception as e:
                logger.warning(f"è·å–æœ€ç»ˆæ¶ˆæ¯æ•°é‡å¤±è´¥: {e}")
            
            if not self.should_stop:
                await self.send_json({
                    "type": "finished",
                    "message": "å¤„ç†å®Œæˆ",
                    "message_count": final_message_count
                })
            
        except asyncio.CancelledError:
            logger.info(f"ç»§ç»­å¤„ç†ä»»åŠ¡è¢«å–æ¶ˆ")
            try:
                await self.send_json({"type": "stream_end"})
            except:
                pass
            
            # ã€é‡è¦ã€‘æ¸…ç†å¯èƒ½ä¸å®Œæ•´çš„çŠ¶æ€
            try:
                await self._cleanup_after_stop(config)
            except Exception as cleanup_error:
                logger.warning(f"åœæ­¢åæ¸…ç†çŠ¶æ€å¤±è´¥: {cleanup_error}")
            
            await self.send_json({"type": "stopped", "message": "å·²åœæ­¢ç”Ÿæˆ"})
        except Exception as e:
            logger.exception(f"ç»§ç»­å¤„ç†å¤±è´¥: {e}")
            await self.send_json({
                "type": "error",
                "message": f"ç»§ç»­å¤„ç†å¤±è´¥: {str(e)}"
            })
        finally:
            self.is_processing = False
            self.current_task = None
            self.should_stop = False

    async def _cleanup_after_stop(self, config):
        """
        åœæ­¢åæ¸…ç†çŠ¶æ€
        ç¡®ä¿ LangGraph çš„çŠ¶æ€æ˜¯å®Œæ•´çš„ï¼Œä»¥ä¾¿ä¸‹æ¬¡å¯¹è¯èƒ½æ­£å¸¸è¿›è¡Œ
        ä¸»è¦å¤„ç†ï¼š
        1. å¦‚æœæœ€åä¸€æ¡æ˜¯ AIMessage å¸¦æœ‰ tool_calls ä½†æ²¡æœ‰å¯¹åº”çš„ ToolMessageï¼Œæ·»åŠ å ä½å“åº”
        2. å¦‚æœæœ€åä¸€æ¡æ˜¯ HumanMessageï¼Œæ·»åŠ ä¸€æ¡ AI ä¸­æ–­æç¤º
        """
        app = await get_async_app()
        from langchain_core.messages import AIMessage, HumanMessage, ToolMessage
        
        try:
            state = await app.aget_state(config)
            if not state or not state.values:
                logger.info("[Cleanup] æ— çŠ¶æ€éœ€è¦æ¸…ç†")
                return
            
            messages = state.values.get("messages", [])
            if not messages:
                logger.info("[Cleanup] æ— æ¶ˆæ¯éœ€è¦æ¸…ç†")
                return
            
            last_msg = messages[-1]
            logger.info(f"[Cleanup] æœ€åä¸€æ¡æ¶ˆæ¯ç±»å‹: {type(last_msg).__name__}")
            
            # æƒ…å†µ1: æœ€åæ˜¯å¸¦æœ‰ tool_calls çš„ AIMessageï¼Œéœ€è¦æ·»åŠ å ä½å·¥å…·å“åº”
            if isinstance(last_msg, AIMessage) and hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:
                logger.info(f"[Cleanup] æ£€æµ‹åˆ°ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨ï¼Œæ·»åŠ å ä½å“åº”")
                fake_tool_messages = []
                for tc in last_msg.tool_calls:
                    tool_call_id = tc.get("id", "")
                    tool_name = tc.get("name", "unknown")
                    fake_tool_messages.append(
                        ToolMessage(
                            content=f"[æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­]",
                            tool_call_id=tool_call_id,
                            name=tool_name
                        )
                    )
                
                if fake_tool_messages:
                    await app.aupdate_state(
                        config, 
                        {"messages": fake_tool_messages}
                    )
                    logger.info(f"[Cleanup] å·²æ·»åŠ  {len(fake_tool_messages)} ä¸ªå ä½å·¥å…·å“åº”")
                    
                    # æ·»åŠ ä¸€æ¡ AI æ¶ˆæ¯è¯´æ˜ä¸­æ–­
                    interrupt_msg = AIMessage(content="[å¯¹è¯è¢«ç”¨æˆ·ä¸­æ–­]")
                    await app.aupdate_state(
                        config,
                        {"messages": [interrupt_msg]}
                    )
                    logger.info("[Cleanup] å·²æ·»åŠ ä¸­æ–­è¯´æ˜æ¶ˆæ¯")
            
            # æƒ…å†µ2: æœ€åæ˜¯ HumanMessageï¼Œè¯´æ˜ AI è¿˜æ²¡æ¥å¾—åŠå›å¤ï¼Œæ·»åŠ ä¸­æ–­è¯´æ˜
            elif isinstance(last_msg, HumanMessage):
                logger.info(f"[Cleanup] æ£€æµ‹åˆ°æœªå®Œæˆçš„ç”¨æˆ·æ¶ˆæ¯ï¼Œæ·»åŠ ä¸­æ–­è¯´æ˜")
                interrupt_msg = AIMessage(content="[å¯¹è¯è¢«ç”¨æˆ·ä¸­æ–­ï¼ŒAI å°šæœªå›å¤]")
                await app.aupdate_state(
                    config,
                    {"messages": [interrupt_msg]}
                )
                logger.info("[Cleanup] å·²æ·»åŠ ä¸­æ–­è¯´æ˜æ¶ˆæ¯")
            
            else:
                logger.info("[Cleanup] çŠ¶æ€å®Œæ•´ï¼Œæ— éœ€æ¸…ç†")
                    
        except Exception as e:
            logger.warning(f"[Cleanup] åœæ­¢åæ¸…ç†çŠ¶æ€æ—¶å‡ºé”™: {e}")

    async def _cleanup_incomplete_tool_calls(self, config):
        """
        æ¸…ç†ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨æ¶ˆæ¯
        å½“é€’å½’é™åˆ¶ä¸­æ–­æ—¶ï¼Œå¯èƒ½å­˜åœ¨ AIMessage æœ‰ tool_calls ä½†æ²¡æœ‰å¯¹åº”çš„ ToolMessage
        """
        app = await get_async_app()
        from langchain_core.messages import AIMessage, ToolMessage
        
        try:
            state = await app.aget_state(config)
            if not state or not state.values:
                return
            
            messages = state.values.get("messages", [])
            if not messages:
                return
            
            last_msg = messages[-1]
            
            # æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¦æ˜¯å¸¦æœ‰ tool_calls çš„ AIMessage
            if isinstance(last_msg, AIMessage) and hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:
                logger.info(f"æ£€æµ‹åˆ°ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨ï¼Œéœ€è¦æ¸…ç†")
                
                # ä¸ºæ¯ä¸ªæœªå®Œæˆçš„ tool_call æ·»åŠ ä¸€ä¸ªå‡çš„ ToolMessage
                fake_tool_messages = []
                for tc in last_msg.tool_calls:
                    tool_call_id = tc.get("id", "")
                    tool_name = tc.get("name", "unknown")
                    fake_tool_messages.append(
                        ToolMessage(
                            content=f"[å·¥å…·è°ƒç”¨è¢«ä¸­æ–­ï¼Œæœªå®Œæˆæ‰§è¡Œ]",
                            tool_call_id=tool_call_id,
                            name=tool_name
                        )
                    )
                
                if fake_tool_messages:
                    # æ›´æ–°çŠ¶æ€æ·»åŠ å‡çš„å·¥å…·å“åº”
                    await app.aupdate_state(
                        config, 
                        {"messages": fake_tool_messages}
                    )
                    logger.info(f"å·²æ·»åŠ  {len(fake_tool_messages)} ä¸ªå ä½å·¥å…·å“åº”")
                    
        except Exception as e:
            logger.warning(f"æ¸…ç†ä¸å®Œæ•´å·¥å…·è°ƒç”¨æ—¶å‡ºé”™: {e}")

    async def _init_graph(self):
        """åˆå§‹åŒ– Agent Graph"""
        self.graph = await get_async_app()
    
    def _get_refresh_types_for_tool(self, tool_name: str) -> list:
        """
        æ ¹æ®å·¥å…·åç§°ç¡®å®šéœ€è¦åˆ·æ–°çš„å‰ç«¯æ•°æ®ç±»å‹
        
        Args:
            tool_name: å·¥å…·åç§°
            
        Returns:
            éœ€è¦åˆ·æ–°çš„æ•°æ®ç±»å‹åˆ—è¡¨ ['events', 'todos', 'reminders']
        """
        # å†™å…¥ç±»å·¥å…·ï¼ˆåˆ›å»ºã€æ›´æ–°ã€åˆ é™¤ã€å®Œæˆï¼‰éœ€è¦åˆ·æ–°å¯¹åº”çš„æ•°æ®
        REFRESH_MAP = {
            # åˆ›å»º/æ›´æ–°/åˆ é™¤é¡¹ç›® - æ ¹æ®é¡¹ç›®ç±»å‹åˆ·æ–°
            'create_item': ['events', 'todos', 'reminders'],  # æ— æ³•é¢„çŸ¥ç±»å‹ï¼Œå…¨éƒ¨åˆ·æ–°
            'update_item': ['events', 'todos', 'reminders'],  # æ— æ³•é¢„çŸ¥ç±»å‹ï¼Œå…¨éƒ¨åˆ·æ–°
            'delete_item': ['events', 'todos', 'reminders'],  # æ— æ³•é¢„çŸ¥ç±»å‹ï¼Œå…¨éƒ¨åˆ·æ–°
            # å¾…åŠä¸“ç”¨
            'complete_todo': ['todos'],
            # äº‹ä»¶ç»„/åˆ†äº«ç»„ï¼ˆå¯èƒ½å½±å“æ—¥å†æ˜¾ç¤ºï¼‰
            'get_event_groups': [],  # åªè¯»
            'get_share_groups': [],  # åªè¯»
            # æŸ¥è¯¢ç±»å·¥å…· - ä¸åˆ·æ–°
            'search_items': [],
            'check_schedule_conflicts': [],
        }
        
        return REFRESH_MAP.get(tool_name, [])
    
    def _parse_query_string(self, query_string: str) -> dict:
        """è§£æ URL æŸ¥è¯¢å‚æ•°"""
        from urllib.parse import unquote
        params = {}
        if query_string:
            for pair in query_string.split("&"):
                if "=" in pair:
                    key, value = pair.split("=", 1)
                    # URL è§£ç å‚æ•°å€¼
                    params[key] = unquote(value)
        return params

    async def _auto_name_session(self, first_message: str):
        """
        è‡ªåŠ¨ä¸ºä¼šè¯ç”Ÿæˆåç§°
        
        Args:
            first_message: ç”¨æˆ·å‘çš„ç¬¬ä¸€æ¡æ¶ˆæ¯
        """
        try:
            from agent_service.models import AgentSession
            from agent_service.agent_graph import get_user_llm
            from agent_service.context_optimizer import get_current_model_config, update_token_usage
            
            # è·å–ä¼šè¯
            session = await database_sync_to_async(
                AgentSession.objects.filter(session_id=self.session_id).first
            )()
            
            if not session:
                logger.warning(f"[è‡ªåŠ¨å‘½å] æ‰¾ä¸åˆ°ä¼šè¯: {self.session_id}")
                return
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»è‡ªåŠ¨å‘½åè¿‡
            if session.is_auto_named:
                return
            
            logger.debug(f"[è‡ªåŠ¨å‘½å] å¼€å§‹ä¸ºä¼šè¯å‘½å: {self.session_id}")
            
            # è®¾ç½®æ­£åœ¨å‘½åçŠ¶æ€
            session.is_naming = True
            await database_sync_to_async(session.save)()
            
            # è·å–å½“å‰æ¨¡å‹ IDï¼ˆç”¨äº token ç»Ÿè®¡ï¼‰
            current_model_id, _ = await database_sync_to_async(get_current_model_config)(self.user)
            
            # é€šçŸ¥å‰ç«¯å¼€å§‹å‘½å
            await self.send_json({
                "type": "naming_start",
                "session_id": self.session_id,
                "message": "æ­£åœ¨ç”Ÿæˆä¼šè¯åç§°..."
            })
            
            try:
                # è·å–ç”¨æˆ·çš„ LLM
                user_llm = await database_sync_to_async(get_user_llm)(self.user)
                
                # æ„å»ºå‘½åæç¤ºè¯
                naming_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ç”¨æˆ·æ¶ˆæ¯ï¼Œä¸ºè¿™æ¬¡å¯¹è¯èµ·ä¸€ä¸ªç®€çŸ­çš„åç§°ï¼ˆ5-15ä¸ªå­—ç¬¦ï¼‰ï¼Œç›´æ¥è¿”å›åç§°ï¼Œä¸è¦æœ‰ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–æ ‡ç‚¹ç¬¦å·ã€‚

ç”¨æˆ·æ¶ˆæ¯: {first_message[:200]}

åç§°:"""
                
                # è°ƒç”¨ LLM ç”Ÿæˆåç§°
                response = await asyncio.to_thread(
                    lambda: user_llm.invoke(naming_prompt)
                )
                
                # ===== Token ç»Ÿè®¡ =====
                if self.user and self.user.is_authenticated:
                    try:
                        input_tokens = 0
                        output_tokens = 0
                        
                        # ä¼˜å…ˆæ£€æŸ¥ usage_metadata
                        if hasattr(response, 'usage_metadata') and response.usage_metadata:
                            usage_metadata = response.usage_metadata
                            if isinstance(usage_metadata, dict):
                                input_tokens = usage_metadata.get('input_tokens', 0) or usage_metadata.get('prompt_tokens', 0)
                                output_tokens = usage_metadata.get('output_tokens', 0) or usage_metadata.get('completion_tokens', 0)
                            else:
                                input_tokens = getattr(usage_metadata, 'input_tokens', 0) or getattr(usage_metadata, 'prompt_tokens', 0)
                                output_tokens = getattr(usage_metadata, 'output_tokens', 0) or getattr(usage_metadata, 'completion_tokens', 0)
                        
                        # å›é€€ï¼šæ£€æŸ¥ response_metadata
                        if not input_tokens and hasattr(response, 'response_metadata'):
                            metadata = response.response_metadata
                            usage = metadata.get('token_usage') or metadata.get('usage') or {}
                            input_tokens = usage.get('prompt_tokens', 0) or usage.get('input_tokens', 0)
                            output_tokens = usage.get('completion_tokens', 0) or usage.get('output_tokens', 0)
                        
                        # å¦‚æœæ— æ³•è·å–å®é™…å€¼ï¼Œä½¿ç”¨ä¼°ç®—å€¼
                        if input_tokens == 0 or output_tokens == 0:
                            logger.warning(f"[è‡ªåŠ¨å‘½å] æ— æ³•ä» API è·å– Token ç”¨é‡ï¼Œé™çº§ä¸ºä¼°ç®—å€¼")
                            if input_tokens == 0:
                                input_tokens = int(len(naming_prompt) / 2.5)  # ç²—ç•¥ä¼°ç®—
                            if output_tokens == 0:
                                output_tokens = 20  # ä¼šè¯åç§°é€šå¸¸å¾ˆçŸ­
                        
                        await database_sync_to_async(update_token_usage)(
                            self.user, input_tokens, output_tokens, current_model_id
                        )
                        logger.debug(f"[è‡ªåŠ¨å‘½å] Token ç»Ÿè®¡å·²æ›´æ–°: in={input_tokens}, out={output_tokens}")
                    except Exception as e:
                        logger.warning(f"[è‡ªåŠ¨å‘½å] Token ç»Ÿè®¡å¤±è´¥: {e}")
                
                # æå–ç”Ÿæˆçš„åç§°
                generated_name = response.content.strip() if hasattr(response, 'content') else str(response).strip()
                
                # é™åˆ¶é•¿åº¦å¹¶æ¸…ç†
                generated_name = generated_name.replace('"', '').replace("'", '').strip()
                if len(generated_name) > 30:
                    generated_name = generated_name[:30] + "..."
                
                # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åç§°
                if not generated_name or len(generated_name) < 2:
                    generated_name = first_message[:20] + ("..." if len(first_message) > 20 else "")
                
                logger.debug(f"[è‡ªåŠ¨å‘½å] ç”Ÿæˆåç§°: {generated_name}")
                
                # æ›´æ–°ä¼šè¯åç§°
                session.name = generated_name
                session.is_naming = False
                session.is_auto_named = True
                await database_sync_to_async(session.save)()
                
                # é€šçŸ¥å‰ç«¯å‘½åå®Œæˆ
                await self.send_json({
                    "type": "naming_end",
                    "session_id": self.session_id,
                    "success": True,
                    "name": generated_name
                })
                
            except Exception as e:
                logger.error(f"[è‡ªåŠ¨å‘½å] ç”Ÿæˆåç§°å¤±è´¥: {e}", exc_info=True)
                
                # ä½¿ç”¨æ¶ˆæ¯å‰ç¼€ä½œä¸ºå¤‡ç”¨åç§°
                fallback_name = first_message[:20] + ("..." if len(first_message) > 20 else "")
                session.name = fallback_name
                session.is_naming = False
                session.is_auto_named = True
                await database_sync_to_async(session.save)()
                
                await self.send_json({
                    "type": "naming_end",
                    "session_id": self.session_id,
                    "success": True,
                    "name": fallback_name,
                    "fallback": True
                })
                
        except Exception as e:
            logger.error(f"[è‡ªåŠ¨å‘½å] å¤±è´¥: {e}", exc_info=True)
            # å‡ºé”™æ—¶ä¹Ÿè¦æ¸…é™¤å‘½åçŠ¶æ€
            try:
                session = await database_sync_to_async(
                    AgentSession.objects.filter(session_id=self.session_id).first
                )()
                if session:
                    session.is_naming = False
                    await database_sync_to_async(session.save)()
            except:
                pass

    async def _update_last_message_preview(self, user_message: str):
        """
        æ›´æ–°ä¼šè¯çš„æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯é¢„è§ˆ
        
        Args:
            user_message: ç”¨æˆ·å‘é€çš„æ¶ˆæ¯å†…å®¹
        """
        try:
            from agent_service.models import AgentSession
            
            session = await database_sync_to_async(
                AgentSession.objects.filter(session_id=self.session_id).first
            )()
            
            if session:
                # æˆªå–é¢„è§ˆï¼ˆ50ä¸ªå­—ç¬¦ï¼‰
                preview = user_message[:50] + ("..." if len(user_message) > 50 else "")
                session.last_message_preview = preview
                await database_sync_to_async(session.save)()
                
        except Exception as e:
            logger.warning(f"[é¢„è§ˆ] æ›´æ–°å¤±è´¥: {e}")

    async def _check_and_summarize(self, messages, config):
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰§è¡Œå†å²æ€»ç»“ï¼Œå¦‚æœéœ€è¦åˆ™æ‰§è¡Œ
        
        Args:
            messages: å½“å‰æ‰€æœ‰æ¶ˆæ¯
            config: Graph é…ç½®
        """
        try:
            from agent_service.models import AgentSession
            from agent_service.context_summarizer import ConversationSummarizer
            from agent_service.context_optimizer import TokenCalculator, get_optimization_config
            from agent_service.agent_graph import get_user_llm, get_current_model_config
            
            session_id = config.get("configurable", {}).get("thread_id", "")
            if not session_id:
                return
            
            # è·å–ä¼˜åŒ–é…ç½®ï¼ˆæ·»åŠ è¯¦ç»†æ—¥å¿—ï¼‰
            logger.debug(f"[æ€»ç»“] å¼€å§‹è·å–ä¼˜åŒ–é…ç½®, user={self.user}, user_id={self.user.id if self.user else 'None'}")
            opt_config = await database_sync_to_async(get_optimization_config)(self.user)
            logger.debug(f"[æ€»ç»“] è·å–åˆ°çš„é…ç½®: {opt_config}")
            
            # è·å–ç”¨æˆ·é…ç½®çš„ LLMï¼ˆç”¨äºæ€»ç»“ï¼‰
            user_llm = await database_sync_to_async(get_user_llm)(self.user)
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ€»ç»“
            if not opt_config.get('enable_summarization', True):
                logger.debug("[æ€»ç»“] æ€»ç»“åŠŸèƒ½å·²ç¦ç”¨")
                return
            
            min_messages = opt_config.get('min_messages_before_summary', 20)
            if not messages or len(messages) < min_messages:
                return
            
            # è·å–ä¼šè¯
            session = await database_sync_to_async(
                AgentSession.objects.filter(session_id=session_id).first
            )()
            if not session:
                return
            
            # è·å–ç°æœ‰æ€»ç»“
            summary_metadata = await database_sync_to_async(session.get_summary_metadata)()
            
            # Token è®¡ç®—å™¨
            calculator = TokenCalculator(
                method=opt_config.get('token_calculation_method', 'estimate')
            )
            
            # è·å–æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£å’Œæ¨¡å‹ ID
            current_model_id, model_config = await database_sync_to_async(get_current_model_config)(self.user)
            context_window = model_config.get('context_window', 128000) if model_config else 128000
            
            # åˆ›å»ºæ€»ç»“å™¨ï¼ˆä½¿ç”¨ç”¨æˆ·é…ç½®çš„ LLMï¼‰
            summarizer = ConversationSummarizer(
                llm=user_llm,
                token_calculator=calculator,
                context_window=context_window,
                target_usage_ratio=opt_config.get('target_usage_ratio', 0.6),
                summary_trigger_ratio=opt_config.get('summary_trigger_ratio', 0.5),
                min_messages_before_summary=min_messages,
                summary_token_ratio=opt_config.get('summary_token_ratio', 0.26),
                target_summary_tokens=opt_config.get('target_summary_tokens', 2000)
            )
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ€»ç»“
            if not summarizer.should_summarize(messages, summary_metadata):
                return
            
            logger.info(f"[æ€»ç»“] è§¦å‘å†å²æ€»ç»“: session={session_id}, messages={len(messages)}")
            
            # è®¾ç½®æ­£åœ¨æ€»ç»“çŠ¶æ€
            await database_sync_to_async(session.set_summarizing)(True)
            
            # é€šçŸ¥å‰ç«¯å¼€å§‹æ€»ç»“
            await self.send_json({
                "type": "summarizing_start",
                "message": "æ­£åœ¨æ€»ç»“å¯¹è¯å†å²..."
            })
            
            try:
                # è®¡ç®—éœ€è¦æ€»ç»“çš„èŒƒå›´
                start_idx, end_idx = summarizer.calculate_summarize_range(messages, summary_metadata)
                messages_to_summarize = messages[start_idx:end_idx]
                
                # è·å–ä¹‹å‰çš„æ€»ç»“ï¼ˆç”¨äºå¢é‡æ›´æ–°ï¼‰
                previous_summary = summary_metadata.get('summary', '') if summary_metadata else None
                
                # æ‰§è¡Œæ€»ç»“ï¼ˆä¼ é€’ user ç”¨äº token ç»Ÿè®¡ï¼‰
                new_summary_metadata = await summarizer.summarize(
                    messages_to_summarize,
                    previous_summary=previous_summary,
                    user=self.user,
                    model_id=current_model_id
                )
                
                if new_summary_metadata:
                    # ä¿å­˜æ€»ç»“ï¼ˆåŒ…å«çœŸå®çš„ input_tokens å’Œ tokens_sourceï¼‰
                    await database_sync_to_async(session.save_summary)(
                        summary_text=new_summary_metadata['summary'],
                        summarized_until=end_idx,
                        summary_tokens=new_summary_metadata['summary_tokens'],
                        summary_input_tokens=new_summary_metadata.get('summary_input_tokens', 0),
                        tokens_source=new_summary_metadata.get('tokens_source', 'estimated')
                    )
                    
                    tokens_source = new_summary_metadata.get('tokens_source', 'estimated')
                    summary_input_tokens = new_summary_metadata.get('summary_input_tokens', 0)
                    
                    logger.debug(
                        f"[æ€»ç»“] å®Œæˆ: æ€»ç»“äº† {end_idx} æ¡æ¶ˆæ¯, "
                        f"output={new_summary_metadata['summary_tokens']}t, "
                        f"input={summary_input_tokens}t, source={tokens_source}"
                    )
                    
                    # é€šçŸ¥å‰ç«¯æ€»ç»“å®Œæˆ
                    await self.send_json({
                        "type": "summarizing_end",
                        "success": True,
                        "summary": new_summary_metadata['summary'],
                        "summarized_until": end_idx,
                        "summary_tokens": new_summary_metadata['summary_tokens']
                    })
                else:
                    await database_sync_to_async(session.set_summarizing)(False)
                    await self.send_json({
                        "type": "summarizing_end",
                        "success": False,
                        "message": "æ€»ç»“ç”Ÿæˆå¤±è´¥"
                    })
                    
            except Exception as e:
                logger.error(f"[æ€»ç»“] æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
                await database_sync_to_async(session.set_summarizing)(False)
                await self.send_json({
                    "type": "summarizing_end",
                    "success": False,
                    "message": f"æ€»ç»“å¤±è´¥: {str(e)}"
                })
                
        except Exception as e:
            logger.error(f"[æ€»ç»“] æ£€æŸ¥å¤±è´¥: {e}", exc_info=True)


class AgentStreamConsumer(AgentConsumer):
    """
    æ”¯æŒæµå¼è¾“å‡ºçš„ Agent Consumer
    ä½¿ç”¨ LangGraph çš„ stream æ–¹æ³•å®ç°æ‰“å­—æœºæ•ˆæœ
    """
    
    async def _process_message(self, content: str):
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶æµå¼è¾“å‡º"""
        self.is_processing = True
        
        try:
            await self.send_json({"type": "processing", "message": "æ­£åœ¨æ€è€ƒ..."})
            
            config = {
                "configurable": {
                    "thread_id": self.session_id,
                    "user": self.user
                }
            }
            
            input_state = {
                "messages": [HumanMessage(content=content)],
                "next": "",
                "active_experts": self.active_experts
            }
            
            # ä½¿ç”¨æµå¼è¾“å‡º
            full_response = ""
            async for event in self._stream_graph(input_state, config):
                event_type = event.get("type")
                
                if event_type == "token":
                    # æµå¼ token
                    token = event.get("content", "")
                    full_response += token
                    await self.send_json({
                        "type": "token",
                        "content": token
                    })
                    
                elif event_type == "tool_call":
                    # å·¥å…·è°ƒç”¨é€šçŸ¥
                    await self.send_json({
                        "type": "tool_call",
                        "name": event.get("name"),
                        "args": event.get("args", {})
                    })
                    
                elif event_type == "tool_result":
                    # å·¥å…·æ‰§è¡Œç»“æœ
                    await self.send_json({
                        "type": "tool_result",
                        "name": event.get("name"),
                        "result": event.get("result", "")
                    })
            
            # å‘é€å®Œæˆä¿¡å·
            await self.send_json({
                "type": "message",
                "content": full_response,
                "finished": True
            })
            
        except Exception as e:
            logger.exception(f"Agent æµå¼è°ƒç”¨å¤±è´¥: {e}")
            await self.send_json({
                "type": "error",
                "message": f"Agent è°ƒç”¨å¤±è´¥: {str(e)}"
            })
        finally:
            self.is_processing = False
    
    async def _stream_graph(self, input_state, config):
        """
        æµå¼è°ƒç”¨ Graph
        æ³¨æ„: è¿™éœ€è¦ graph æ”¯æŒæµå¼è¾“å‡º
        ç›®å‰ä½¿ç”¨ç®€åŒ–å®ç°ï¼Œåç»­å¯ä»¥æ‰©å±•ä¸ºçœŸæ­£çš„æµå¼
        """
        # ç®€åŒ–å®ç°ï¼šç›´æ¥è°ƒç”¨ invoke ç„¶åè¿”å›å®Œæ•´å“åº”
        result = await self._invoke_graph(input_state, config)
        
        if result and "messages" in result:
            for msg in reversed(result["messages"]):
                if isinstance(msg, AIMessage):
                    # æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼ˆåˆ†å—å‘é€ï¼‰
                    content = msg.content
                    chunk_size = 10  # æ¯æ¬¡å‘é€çš„å­—ç¬¦æ•°
                    
                    for i in range(0, len(content), chunk_size):
                        chunk = content[i:i+chunk_size]
                        yield {"type": "token", "content": chunk}
                        await asyncio.sleep(0.02)  # æ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ
                    break
